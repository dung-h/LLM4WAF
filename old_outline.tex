\begin{document}

\maketitle

\tableofcontents


% =========================================================
% SECTION 1: BACKGROUND & RELATED WORK (Kiến thức nền)
% =========================================================

% ========================================
% PROMPT CHO AGENT VIẾT SECTION 1
% ========================================
% Bạn đang viết Section 1 của luận văn tiếng Việt về "LLM-based Red Agent for WAF Bypass Testing".
% Section này cung cấp kiến thức nền tảng toàn diện cần thiết để hiểu nghiên cứu.
%
% BỐI CẢNH:
% - Đối tượng đọc: Giảng viên chấm luận văn và sinh viên ngành Khoa học Máy tính tại Việt Nam
% - Ngôn ngữ: TIẾNG VIỆT (phong cách học thuật)
% - Định dạng: LaTeX với citations đầy đủ
% - Phạm vi: CHỈ viết kiến thức nền, KHÔNG viết về phương pháp/thực nghiệm
%
% CẤU TRÚC SECTION:
%
% 1.1 Các lỗ hổng bảo mật ứng dụng web cơ bản
%   1.1.1 SQL Injection (SQLi)
%     - Định nghĩa, các vector tấn công (In-band, Inferential, Out-of-band)
%     - Các kỹ thuật phổ biến: Boolean-based, Union-based, Error-based, Time-based
%     - Ví dụ thực tế với code dễ bị tấn công
%     - Tác động: Đánh cắp dữ liệu, bypass xác thực, thao túng database
%   1.1.2 Cross-Site Scripting (XSS)
%     - Định nghĩa, ba loại: Reflected, Stored, DOM-based
%     - Kịch bản tấn công: Đánh cắp cookie, chiếm session, phishing
%     - Các payload phổ biến với ví dụ obfuscation
%     - Tác động & cơ chế phòng thủ (CSP, input validation)
%   1.1.3 OS Command Injection
%     - Định nghĩa, các hàm dễ bị tấn công
%     - Kỹ thuật: Command chaining, substitution
%     - Tác động: Chiếm quyền hệ thống, đánh cắp dữ liệu
%
% 1.2 Web Application Firewall (WAF)
%   1.2.1 ModSecurity
%     - ModSecurity là gì? Kiến trúc như module Apache/Nginx
%     - Pipeline xử lý rule (5 phases)
%     - Cấu hình & mô hình Anomaly scoring
%   1.2.2 OWASP Core Rule Set (CRS)
%     - Paranoia Levels (PL1-PL4) với đánh đổi
%     - Các nhóm rule (Protocol, Attack detection, Data leakage)
%     - Ngưỡng anomaly scoring
%   1.2.3 Phát hiện dựa trên quy tắc & Hạn chế
%     - Cách WAF dựa trên regex hoạt động
%     - Ưu điểm: Nhanh, ít tài nguyên, đã được chứng minh
%     - Hạn chế QUAN TRỌNG: Không phát hiện được pattern mới, dễ bị obfuscation
%     - Động lực sử dụng LLM (cầu nối đến nghiên cứu)
%
% 1.3 Các kỹ thuật che giấu payload (SECTION QUAN TRỌNG)
%   1.3.1 Kỹ thuật mã hóa
%     - URL Encoding: Single, Double, Triple với ví dụ
%     - Unicode & Hex encoding với ví dụ bypass
%     - Bảng so sánh original vs encoded payloads
%   1.3.2 Obfuscation dựa trên Comment
%     - SQL: SE/**/LECT, UN/**/ION, version-specific comments
%     - XSS: Chèn comment vào tags
%     - Biến thể whitespace
%   1.3.3 Thao túng Case & Whitespace
%     - Trộn case, chèn whitespace, concatenation
%   1.3.4 Polyglot Payloads & Kỹ thuật nâng cao
%     - Payload đa ngữ cảnh, WAF fingerprinting
%
% 1.4 Môi trường kiểm thử: DVWA
%   1.4.1 Tổng quan DVWA
%     - Mục đích, kiến trúc (PHP+MySQL)
%     - Các security level: Low, Medium, High, Impossible
%     - Modules được test: SQLi, XSS, Command Injection
%     - Tại sao dùng DVWA cho nghiên cứu này?
%
% 1.5 LLM cho các tác vụ bảo mật
%   1.5.1 Transformer Architecture (THÊM MỚI - Kiến thức nền)
%     - Self-attention mechanism
%     - Encoder-Decoder vs Decoder-only
%     - Positional encoding
%     - Multi-head attention
%   1.5.2 Kỹ thuật Fine-tuning
%     - PEFT, LoRA (low-rank adaptation với công thức)
%     - Quantization (4-bit)
%   1.5.3 Reinforcement Learning cho LLM
%     - RL Framework: Agent, Environment, Action, State, Reward
%     - Thuật toán REINFORCE
%     - Tại sao dùng RL cho WAF bypass?
%
% YÊU CẦU OUTPUT:
% 1. Viết HOÀN TOÀN BẰNG TIẾNG VIỆT học thuật, tự nhiên, mạch lạc
% 2. Dùng định dạng LaTeX với các lệnh \subsection, \subsubsection, \paragraph
% 3. Thêm \cite{key} xuyên suốt văn bản nơi cần trích dẫn
% 4. Thêm comment [TODO: Chèn Hình X - Mô tả] cho figures
% 5. Thêm comment [TODO: Chèn Bảng X - Mô tả] cho tables
% 6. Ví dụ code dùng môi trường \begin{verbatim}...\end{verbatim} hoặc \texttt{}
% 7. Giải thích thuật ngữ kỹ thuật rõ ràng (có thể để tiếng Anh trong ngoặc)
% 8. Giữ giọng văn học thuật, tránh ngôn ngữ marketing
% 9. Tổng độ dài: Khoảng 15-20 trang
%
% ĐỊNH DẠNG REFERENCES:
% Cuối Section 1, thêm khối \begin{thebibliography}{99} với các entry như:
%
% \bibitem{owaspCRS}
% OWASP. \textit{"OWASP ModSecurity Core Rule Set (CRS)."} Online Resource, 
% \url{https://coreruleset.org/}. (Truy cập: 2024).
%
% \bibitem{modsecurity}
% Trustwave SpiderLabs. \textit{"ModSecurity: Open Source Web Application Firewall."}
% \url{https://github.com/SpiderLabs/ModSecurity}. (Truy cập: 2024).
%
% \bibitem{sqli-owasp}
% OWASP. \textit{"SQL Injection."} OWASP Foundation,
% \url{https://owasp.org/www-community/attacks/SQL_Injection}. (Truy cập: 2024).
%
% \bibitem{xss-owasp}
% OWASP. \textit{"Cross-Site Scripting (XSS)."} OWASP Foundation,
% \url{https://owasp.org/www-community/attacks/xss/}. (Truy cập: 2024).
%
% \bibitem{dvwa}
% Damn Vulnerable Web Application (DVWA). \textit{"DVWA - Damn Vulnerable Web Application."}
% \url{https://github.com/digininja/DVWA}. (Truy cập: 2024).
%
% \bibitem{lora}
% Hu, Edward J., et al. \textit{"LoRA: Low-Rank Adaptation of Large Language Models."}
% arXiv preprint arXiv:2106.09685 (2021).
%
% \bibitem{rl-intro}
% Sutton, Richard S., and Andrew G. Barto. \textit{"Reinforcement Learning: An Introduction."}
% MIT Press, 2018.
%
% Bao gồm 15-20 references liên quan:
% - Bảo mật web (SQLi, XSS, Command Injection)
% - Công nghệ WAF (ModSecurity, CRS, rule-based detection)
% - Kỹ thuật obfuscation & WAF bypass
% - Cơ bản về LLM (Transformers, fine-tuning)
% - Papers về PEFT/LoRA
% - Reinforcement Learning
% - DVWA và công cụ penetration testing
%
% SỬ DỤNG \cite{key} TRONG VĂN BẢN, ví dụ:
% "ModSecurity \cite{modsecurity} là một WAF mã nguồn mở..."
% "Theo OWASP \cite{sqli-owasp}, SQL Injection xảy ra khi..."
%
% LƯU Ý QUAN TRỌNG:
% - KHÔNG viết về phương pháp, dataset, hay thực nghiệm (đó là Section 2+)
% - KHÔNG đề cập kết quả training hay performance metrics
% - TẬP TRUNG giải thích các khái niệm nền tảng một cách thấu đáo
% - Dùng nhiều ví dụ minh họa
% - Trích dẫn nguồn đầy đủ xuyên suốt văn bản
% - Viết HOÀN TOÀN BẰNG TIẾNG VIỆT, chỉ giữ thuật ngữ tiếng Anh trong ngoặc khi cần
% ========================================

\section{Kiến thức nền tảng}
\label{sec:background}

% TODO: Agent writes subsections 1.1 - 1.5 following the prompt above
% This section should be approximately 15-20 pages covering:
% - Web security fundamentals (SQLi, XSS, OS Injection)
% - WAF technology (ModSecurity, OWASP CRS, limitations)
% - Payload obfuscation techniques (encoding, comments, case manipulation, polyglot)
% - DVWA testing environment
% - LLM fundamentals (overview, fine-tuning, RL)



% =========================================================
% SECTION 2: CÁC MÔ HÌNH LLM ĐƯỢC SỬ DỤNG (NGƯỜI 1)
% =========================================================

% ========================================
% PROMPT CHO AGENT VIẾT SECTION 2
% ========================================
% Bạn đang viết Section 2 của luận văn tiếng Việt về các mô hình LLM được sử dụng.
% Section này giới thiệu chi tiết 3 họ mô hình: Gemma 2, Phi-3, Qwen 2.5
%
% BỐI CẢNH:
% - Người đọc đã hiểu cơ bản về Transformer architecture từ Section 1
% - Cần giải thích tại sao chọn 3 mô hình này
% - Cần so sánh architecture, tokenizer, capabilities
% - Ngôn ngữ: TIẾNG VIỆT (phong cách học thuật)
%
% CẤU TRÚC SECTION:
%
% 2.1 Tổng quan về lựa chọn mô hình
%   - Tiêu chí lựa chọn:
%     * Kích thước phù hợp với 16GB VRAM (2B-7B parameters)
%     * Hỗ trợ instruction fine-tuning tốt
%     * Đa dạng kiến trúc để so sánh
%     * Open-source, có sẵn trên HuggingFace
%   - Bao phủ 3 size classes:
%     * Small: Gemma 2 2B
%     * Medium: Qwen 2.5 3B, Phi-3 Mini (3.8B)
%   - Bảng so sánh tổng quan (TODO: Insert Table)
%
% 2.2 Gemma 2 2B
%   2.2.1 Tổng quan
%     - Nguồn gốc: Google DeepMind (2024)
%     - Họ mô hình: Gemma 2 (2B, 9B, 27B variants)
%     - Phiên bản sử dụng: google/gemma-2-2b-it (instruction-tuned)
%   2.2.2 Kiến trúc
%     - Base architecture: Decoder-only Transformer
%     - Layers: 26 transformer blocks
%     - Hidden size: 2304
%     - Attention heads: 8 (multi-query attention - MQA)
%     - Sliding window attention (4096 tokens)
%     - RoPE (Rotary Position Embedding)
%     - GeGLU activation
%   2.2.3 Tokenizer
%     - Type: SentencePiece (Unigram)
%     - Vocab size: 256,000 tokens
%     - Context length: 8192 tokens
%     - Đặc điểm: Tốt cho multilingual, hiệu quả với code
%   2.2.4 Ưu nhược điểm cho task
%     - Ưu điểm:
%       * Nhỏ gọn nhất (2B params)
%       * Train nhanh, inference nhanh
%       * Tốt cho edge deployment
%     - Nhược điểm:
%       * Capacity hạn chế cho reasoning phức tạp
%       * Ít parameters -> khó học pattern tinh vi
%   [TODO: Chèn Bảng - Gemma 2 2B Specifications]
%
% 2.3 Phi-3 Mini
%   2.3.1 Tổng quan
%     - Nguồn gốc: Microsoft Research (2024)
%     - Họ mô hình: Phi-3 (Mini, Small, Medium)
%     - Phiên bản sử dụng: microsoft/Phi-3-mini-4k-instruct
%     - Đặc điểm nổi bật: "Small Language Model" với performance vượt mong đợi
%   2.3.2 Kiến trúc
%     - Base: Decoder-only Transformer (GPT-style)
%     - Parameters: 3.8B
%     - Layers: 32
%     - Hidden size: 3072
%     - Attention heads: 32
%     - GQA (Grouped Query Attention)
%     - RoPE positional embedding
%   2.3.3 Tokenizer
%     - Type: tiktoken (GPT-style BPE)
%     - Vocab size: 32,064 tokens
%     - Context length: 4096 tokens (4k variant)
%     - Đặc điểm: Tối ưu cho tiếng Anh, code, technical content
%   2.3.4 Ưu nhược điểm cho task
%     - Ưu điểm:
%       * Balance tốt giữa size và capability
%       * Được train trên high-quality data
%       * Excellent instruction following
%       * Tốt cho reasoning tasks
%     - Nhược điểm:
%       * Context length hạn chế (4k)
%       * Tokenizer ít hiệu quả với non-English
%   [TODO: Chèn Bảng - Phi-3 Mini Specifications]
%
% 2.4 Qwen 2.5 3B
%   2.4.1 Tổng quan
%     - Nguồn gốc: Alibaba Cloud (2024)
%     - Họ mô hình: Qwen 2.5 (0.5B, 1.5B, 3B, 7B, 14B, 72B)
%     - Phiên bản sử dụng: Qwen/Qwen2.5-3B-Instruct
%     - Đặc điểm: Multilingual, tốt cho code generation
%   2.4.2 Kiến trúc
%     - Base: Decoder-only Transformer
%     - Parameters: 3B
%     - Layers: 36
%     - Hidden size: 2048
%     - Attention heads: 16
%     - GQA (Grouped Query Attention) với 2 KV heads
%     - RoPE with extended context
%     - SwiGLU activation
%   2.4.3 Tokenizer
%     - Type: tiktoken-based (custom BPE)
%     - Vocab size: 151,936 tokens
%     - Context length: 32,768 tokens (extended)
%     - Đặc điểm: Excellent multilingual support, hiệu quả với Chinese + English
%   2.4.4 Ưu nhược điểm cho task
%     - Ưu điểm:
%       * Context length rất lớn (32k)
%       * Multilingual capability
%       * Tốt cho code & technical content
%       * Strong instruction following
%     - Nhược điểm:
%       * Lớn hơn Gemma 2 2B -> train chậm hơn
%       * VRAM usage cao hơn
%   [TODO: Chèn Bảng - Qwen 2.5 3B Specifications]
%
% 2.5 So sánh và lựa chọn cho từng phase
%   - Bảng so sánh toàn diện:
%     * Parameters, Layers, Context length
%     * Tokenizer type & vocab size
%     * VRAM requirements (4-bit quantized)
%     * Training speed estimate
%   - Lý do train cả 3:
%     * So sánh performance trên cùng task
%     * Đánh giá trade-off: size vs capability
%     * Validate approach không bị overfitting vào 1 architecture
%   [TODO: Chèn Bảng - Model Comparison Matrix]
%
% YÊU CẦU OUTPUT:
% 1. Viết HOÀN TOÀN BẰNG TIẾNG VIỆT
% 2. Dùng LaTeX format với \subsection, \subsubsection
% 3. Thêm \cite{} cho mỗi mô hình (Gemma paper, Phi-3 paper, Qwen paper)
% 4. Tạo 4 bảng specifications (1 cho mỗi model + 1 comparison)
% 5. Giải thích kỹ thuật rõ ràng (GQA, MQA, RoPE, SwiGLU...)
% 6. Độ dài: 8-10 trang
%
% REFERENCES CẦN THÊM:
% \bibitem{gemma2}
% Google DeepMind. \textit{"Gemma 2: Improving Open Language Models at a Practical Size."}
% Technical Report, 2024. \url{https://huggingface.co/google/gemma-2-2b-it}.
%
% \bibitem{phi3}
% Microsoft Research. \textit{"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone."}
% arXiv preprint arXiv:2404.14219 (2024).
%
% \bibitem{qwen25}
% Alibaba Cloud. \textit{"Qwen2.5: A Party of Foundation Models."}
% Technical Report, 2024. \url{https://qwenlm.github.io/blog/qwen2.5/}.
%
% LƯU Ý:
% - Giải thích thuật ngữ kỹ thuật (GQA, MQA, RoPE) trong ngoặc tiếng Anh
% - So sánh rõ ràng để người đọc hiểu tại sao chọn 3 models này
% - Không đề cập kết quả training/evaluation (phần sau)
% ========================================

\section{Các mô hình ngôn ngữ lớn được sử dụng}
\label{sec:models}

% TODO: Agent writes subsections 2.1 - 2.5 following the prompt above
% This section should be approximately 8-10 pages covering:
% - Rationale for model selection
% - Detailed architecture of Gemma 2 2B, Phi-3 Mini, Qwen 2.5 3B
% - Tokenizer specifications
% - Comparison tables
% - Pros/cons for WAF bypass task


% =========================================================
% SECTION 3: DATASET & EXPERIMENTAL SETUP (NGƯỜI 2)
% =========================================================

% ========================================
% PROMPT CHO AGENT VIẾT SECTION 3
% ========================================
% Bạn đang viết Section 3 của luận văn tiếng Việt về xây dựng dataset và thiết lập thực nghiệm.
% Section này giải thích chi tiết quy trình tạo dữ liệu và môi trường kiểm thử.
%
% BỐI CẢNH:
% - Người đọc đã hiểu về WAF, payload obfuscation, và LLM từ Section 1-2
% - Cần giải thích rõ ràng quy trình 2-phase dataset construction
% - Có sẵn analysis scripts và data files để tham khảo
% - Ngôn ngữ: TIẾNG VIỆT (phong cách học thuật)
%
% DATASETS CÓ SẴN (QUAN TRỌNG):
% 1. data/processed/phase1_balanced_10k.jsonl (10,000 samples)
% 2. data/processed/phase2_with_replay_24k.jsonl (24,000 samples)
%
% ANALYSIS SCRIPTS ĐÃ TẠO:
% 1. scripts/analysis/analyze_phase1_creation.py
% 2. scripts/analysis/analyze_phase2_creation.py
% 3. scripts/analysis/analyze_technique_distribution.py
% 4. scripts/analysis/analyze_synthetic_quality.py
% 5. scripts/analysis/demonstrate_dataset_construction.py
%
% OUTPUT FILES (ĐÃ SINH):
% - reports/dataset_analysis/phase1_analysis.json
% - reports/dataset_analysis/phase2_analysis.json
% - reports/dataset_analysis/synthetic_quality_analysis.json
% - reports/dataset_analysis/construction_demo.json
% - reports/dataset_analysis/technique_distribution_phase1.csv (509 techniques)
% - reports/dataset_analysis/technique_distribution_phase2.csv (532 techniques)
% - 7 PNG visualizations (technique distribution, attack type, payload length, quality metrics)
%
% CẤU TRÚC SECTION:
%
% 3.1 Tổng quan về Dataset
%   3.1.1 Mục tiêu xây dựng dataset
%     - Sinh payload tấn công WAF đa dạng
%     - Bao phủ nhiều kỹ thuật obfuscation
%     - Hỗ trợ 3 loại tấn công: SQLi, XSS, OS Command Injection
%   3.1.2 Attack Type Distribution
%     - SQLI: SQL Injection attacks
%     - XSS: Cross-Site Scripting attacks
%     - OS_INJECTION: OS Command Injection attacks
%     - Trích dẫn số liệu từ phase1_analysis.json và phase2_analysis.json
%   3.1.3 Technique Coverage
%     - Phase 1: 509 unique techniques
%     - Phase 2: 532 unique techniques (+23 new from observations)
%     - Các nhóm kỹ thuật chính:
%       * URL encoding variants (single, double, triple)
%       * Comment-based obfuscation
%       * Case manipulation
%       * Unicode/Hex encoding
%       * Polyglot payloads
%     [TODO: Chèn Bảng - Attack Type Distribution Phase 1 vs Phase 2]
%     [TODO: Chèn Hình - technique_dist_phase1.png và technique_dist_phase2.png]
%
% 3.2 Phase 1: Initial Payload Generation
%   3.2.1 Quy trình tạo dữ liệu
%     - Nguồn: Gemini 1.5 Flash và Deepseek (LLM generation)
%     - Input: Technique name + Attack type
%     - Output: Payload candidates
%     - Prompt template:
%       \begin{verbatim}
%       Generate WAF-evasion payloads.
%       Target: {attack_type} on ModSecurity PL1.
%       Technique: {technique}
%       IMPORTANT: Generate ONLY the payload code.
%       \end{verbatim}
%   3.2.2 Quy trình kiểm thử và lọc
%     - Test trên ModSecurity PL1 (DVWA backend)
%     - Phân loại: PASSED (bypass thành công) / BLOCKED (bị chặn)
%     - Lưu kết quả vào metadata
%   3.2.3 Balanced Subsetting
%     - Từ 39,155 samples ban đầu → 10,000 samples balanced
%     - Giữ nguyên 509 unique techniques (100% coverage)
%     - Chiến lược: Stratified sampling theo technique
%     - Mục đích: Tránh imbalance, tối ưu training time
%   3.2.4 Data Format (JSONL)
%     - Schema Phase 1:
%       \begin{verbatim}
%       {
%         "messages": [
%           {"role": "user", "content": "Generate..."},
%           {"role": "assistant", "content": "payload"}
%         ],
%         "technique": "Double URL Encode",
%         "attack_type": "SQLI",
%         "result": "passed" / "blocked"
%       }
%       \end{verbatim}
%   3.2.5 Phân tích thống kê Phase 1
%     - Trích dẫn từ reports/dataset_analysis/phase1_analysis.json:
%       * Total samples: 10,000
%       * Unique techniques: 509
%       * Attack distribution: SQLI 47.5%, XSS 52.0%, OS_INJECTION 0.5%
%       * Bypass success rate: 51.02%
%       * Avg payload length: 105.40 characters
%     [TODO: Chèn Hình - attack_type_phase1.png]
%     [TODO: Chèn Hình - payload_length_phase1.png]
%
% 3.3 Phase 2: Observation-based Refinement
%   3.3.1 Động lực cho Phase 2
%     - Phase 1 chỉ dạy syntax và basic obfuscation
%     - Thiếu context về WAF behavior (BLOCKED vs PASSED patterns)
%     - Cần LLM học từ observations để refine strategy
%   3.3.2 Observation Collection Mechanism
%     - Từ Phase 1 testing, thu thập:
%       * BLOCKED examples: Payloads bị WAF chặn
%       * PASSED examples: Payloads bypass thành công
%     - Group by technique + attack_type
%     - Tạo observation history cho mỗi technique
%   3.3.3 Prompt Template với Observations
%     - Enhanced prompt format:
%       \begin{verbatim}
%       Generate WAF-evasion payloads.
%       Target: {attack_type} on ModSecurity PL1.
%       Technique: {technique}
%       
%       [Observations]
%       - BLOCKED: [examples of blocked payloads]
%       - PASSED: [examples of passed payloads]
%       
%       Instruction: Generate NEW payload learning from PASSED patterns.
%       Output ONLY the payload.
%       \end{verbatim}
%   3.3.4 Replay Buffer Strategy
%     - Tránh catastrophic forgetting từ Phase 1
%     - Lấy 4,000 samples từ Phase 1 (relabeled)
%     - Mix với 20,000 observations mới
%     - Total Phase 2: 24,000 samples (replay rate 16.7%)
%   3.3.5 Data Format Phase 2
%     - Schema với observations:
%       \begin{verbatim}
%       {
%         "messages": [
%           {
%             "role": "user", 
%             "content": "Target: SQLI...\nTechnique: ...\n\n[Observations]..."
%           },
%           {"role": "assistant", "content": "payload"}
%         ],
%         "relabeled": true/false  // Indicates replay buffer
%       }
%       \end{verbatim}
%     - Note: Technique và attack_type được embed trong user prompt
%   3.3.6 Phân tích thống kê Phase 2
%     - Trích dẫn từ reports/dataset_analysis/phase2_analysis.json:
%       * Total samples: 24,000 (20k observations + 4k replay)
%       * Unique techniques: 532 (+23 new techniques learned)
%       * Attack distribution: SQLI 55.3%, XSS 37.1%, OS_INJECTION 7.7%
%       * Bypass success rate: 51.82%
%       * Avg payload length: 108.46 characters (+2.9% complexity)
%     [TODO: Chèn Hình - attack_type_phase2.png]
%     [TODO: Chèn Hình - payload_length_phase2.png]
%   3.3.7 Evolution Analysis
%     - So sánh Phase 1 vs Phase 2:
%       * Technique expansion: 509 → 532
%       * Payload complexity tăng 2.9%
%       * Attack type shift: Tăng SQLI và OS_INJECTION (từ observations)
%     [TODO: Chèn Bảng - Phase 1 vs Phase 2 Comparison]
%
% 3.4 Phân tích chất lượng dữ liệu
%   3.4.1 Diversity Metrics
%     - Trích từ synthetic_quality_analysis.json:
%       * Phase 1 uniqueness rate: 90.45% (9,045/10,000 unique payloads)
%       * Phase 2 uniqueness rate: 51.88% (do replay buffer)
%       * Technique entropy: Phase 1 = 7.24, Phase 2 = 8.17 (higher diversity)
%     - Ý nghĩa: Phase 2 có diversity cao hơn nhờ observations
%   3.4.2 Validity Metrics
%     - WAF bypass success rate:
%       * Phase 1: 51.02%
%       * Phase 2: 51.82%
%     - Maintained balance (không bias về PASSED hay BLOCKED)
%   3.4.3 Complexity Metrics
%     - Payload length evolution:
%       * Phase 1: avg 105.40 chars
%       * Phase 2: avg 108.46 chars (+2.9%)
%     - Encoding depth (URL encoding layers):
%       * Phase 1: avg 2.3 layers
%       * Phase 2: avg 2.5 layers
%     - Special character density:
%       * Phase 1: 23.4%
%       * Phase 2: 25.1%
%   3.4.4 Bias Analysis
%     - Attack type balance:
%       * Phase 1: SQLI 47.5%, XSS 52%, OS 0.5%
%       * Phase 2: SQLI 55.3%, XSS 37.1%, OS 7.7%
%     - Top-10 technique concentration:
%       * Phase 1: 32.5% (acceptable diversity)
%       * Phase 2: 28.7% (better distribution)
%     [TODO: Chèn Hình - quality_metrics.png (4-panel comparison)]
%
% 3.5 Môi trường WAF và kịch bản kiểm thử
%   3.5.1 Kiến trúc Docker Compose
%     - File: docker-compose.multiwaf.yml
%     - Services:
%       * app: DVWA (PHP+MySQL) - Ứng dụng đích
%       * modsec_pl1: ModSecurity CRS Paranoia Level 1
%       * modsec_pl4: ModSecurity CRS Paranoia Level 4 (paranoid)
%       * coraza: Coraza WAF (alternative implementation)
%     - Network flow:
%       \begin{verbatim}
%       Client → WAF (port 8001/8004/8005) → DVWA (port 80)
%       \end{verbatim}
%     [TODO: Chèn Hình - Docker architecture diagram]
%   3.5.2 ModSecurity Configuration
%     - Paranoia Level 1 (PL1):
%       * Anomaly threshold: 5
%       * False positive rate: Low
%       * Coverage: Basic attacks
%       * Use case: Production-ready, RL training environment
%     - Paranoia Level 4 (PL4):
%       * Anomaly threshold: 5 (stricter rules)
%       * False positive rate: High
%       * Coverage: Comprehensive
%       * Use case: Evaluation only (not for RL training)
%   3.5.3 DVWA Integration
%     - Security level: LOW (no server-side protection)
%     - Vulnerable endpoints tested:
%       * /vulnerabilities/sqli/ - SQL Injection (GET parameter)
%       * /vulnerabilities/xss_r/ - Reflected XSS
%       * /vulnerabilities/exec/ - Command Injection
%     - Login credentials: admin/password
%     - Session management: PHP sessions
%   3.5.4 Coraza WAF
%     - Alternative WAF implementation (Go-based)
%     - Uses OWASP CRS rules (same as ModSecurity)
%     - Purpose: Cross-validation (test generalization)
%   3.5.5 Test Scenarios
%     - Scenario 1: PL1 Bypass Testing (RL training)
%       * Environment: modsec_pl1
%       * Metrics: Pass rate, Success rate
%     - Scenario 2: PL4 Stress Testing (evaluation)
%       * Environment: modsec_pl4
%       * Metrics: Pass rate under strict rules
%     - Scenario 3: Cross-WAF Testing (generalization)
%       * Environment: coraza
%       * Metrics: Transferability of learned strategies
%   3.5.6 Evaluation Metrics
%     - Pass Rate: % payloads NOT blocked by WAF
%       Formula: (Passed requests) / (Total requests) × 100%
%     - Success Rate: % payloads bypass WAF AND exploit successfully
%       Formula: (Successful exploits) / (Total requests) × 100%
%     - Diversity Score: Unique technique coverage
%       Formula: (Unique techniques used) / (Total available techniques)
%     [TODO: Chèn Bảng - Metrics Definition Table]
%
% YÊU CẦU OUTPUT:
% 1. Viết HOÀN TOÀN BẰNG TIẾNG VIỆT
% 2. Dùng LaTeX format với \subsection, \subsubsection, \paragraph
% 3. Trích dẫn số liệu CHÍNH XÁC từ JSON files
% 4. Chèn code examples trong \begin{verbatim}...\end{verbatim}
% 5. Tạo bảng so sánh Phase 1 vs Phase 2
% 6. Tham chiếu đến 7 PNG visualizations
% 7. Giải thích rõ replay buffer strategy
% 8. Mô tả chi tiết Docker architecture
% 9. Độ dài: 15-20 trang
%
% HƯỚNG DẪN SỬ DỤNG ANALYSIS SCRIPTS (CHO NGƯỜI VIẾT):
% ```bash
% # Chạy analysis scripts để tạo reports
% python scripts/analysis/analyze_phase1_creation.py
% python scripts/analysis/analyze_phase2_creation.py
% python scripts/analysis/analyze_technique_distribution.py
% python scripts/analysis/analyze_synthetic_quality.py
% python scripts/analysis/demonstrate_dataset_construction.py
%
% # Output files sẽ được tạo tại:
% # - reports/dataset_analysis/*.json
% # - reports/dataset_analysis/*.csv
% # - reports/dataset_analysis/figures/*.png
% ```
%
% DATA FILES LOCATIONS:
% - Phase 1: data/processed/phase1_balanced_10k.jsonl
% - Phase 2: data/processed/phase2_with_replay_24k.jsonl
% - Analysis outputs: reports/dataset_analysis/
%
% REFERENCES CẦN THÊM:
% \bibitem{docker}
% Docker Inc. \textit{"Docker: Containerization Platform."}
% \url{https://www.docker.com/}. (Truy cập: 2024).
%
% \bibitem{coraza}
% Coraza Project. \textit{"Coraza Web Application Firewall."}
% \url{https://coraza.io/}. (Truy cập: 2024).
%
% LƯU Ý QUAN TRỌNG:
% - SỬ DỤNG SỐ LIỆU THỰC TẾ từ JSON files, KHÔNG tự bịa
% - Giải thích RÕ RÀNG tại sao cần Phase 2 (observation-based learning)
% - Nhấn mạnh replay buffer tránh catastrophic forgetting
% - Phân biệt rõ: PL1 cho RL training, PL4/Coraza chỉ cho evaluation
% - Chèn đầy đủ 7 figures đã generate
% ========================================

\section{Xây dựng dữ liệu và thiết lập thực nghiệm}
\label{sec:dataset}

% TODO: Agent writes subsections 3.1 - 3.5 following the prompt above
% This section should be approximately 15-20 pages covering:
% - Dataset overview with real statistics
% - Phase 1 & Phase 2 construction process
% - Data quality analysis (diversity, validity, complexity, bias)
% - Docker WAF environment setup
% - Test scenarios and evaluation metrics



% =========================================================
% SECTION 4: TRAINING & EVALUATION (NGƯỜI 3)
% =========================================================

% ========================================
% PROMPT CHO AGENT VIẾT SECTION 4
% ========================================
% Bạn đang viết Section 4 của luận văn tiếng Việt về quy trình huấn luyện và đánh giá.
% Section này mô tả pipeline training, phân tích loss, và kết quả evaluation.
%
% BỐI CẢNH:
% - Người đọc đã hiểu về models (Section 2) và datasets (Section 3)
% - QUAN TRỌNG: Training chưa hoàn thành, chỉ viết phần lý thuyết + placeholder
% - Khi có kết quả, sẽ update vào các placeholder
% - Ngôn ngữ: TIẾNG VIỆT (phong cách học thuật)
%
% CẤU TRÚC SECTION:
%
% 4.1 Pipeline huấn luyện tổng quan
%   4.1.1 Kiến trúc 3-phase training
%     - Phase 1: Supervised Fine-Tuning (SFT) - Basic payload generation
%     - Phase 2: Supervised Fine-Tuning (SFT) - Observation-enhanced
%     - Phase 3: Reinforcement Learning (RL) - Live WAF interaction
%     [TODO: Chèn Hình - Training pipeline diagram]
%   4.1.2 Cấu hình phần cứng
%     - Remote server: 16GB VRAM GPU
%     - Models: Gemma 2 2B, Phi-3 Mini 3.8B, Qwen 2.5 3B
%     - Quantization: 4-bit (bitsandbytes)
%     - LoRA adapters: rank=16, alpha=32
%   4.1.3 Hyperparameters
%     - Trích từ configs/remote_*_phase*.yaml:
%       * Learning rate: 2e-4 (Phase 1), 1e-4 (Phase 2), 1e-6 (Phase 3 RL)
%       * Batch size: Model-dependent (Gemma: 4, Phi-3: 2, Qwen: 2)
%       * Gradient accumulation: 4-8 steps (effective batch = 16)
%       * Epochs: Phase 1 = 3, Phase 2 = 2, Phase 3 = 150 episodes
%       * Max sequence length: 1024 tokens
%       * Optimizer: paged_adamw_8bit
%       * Scheduler: cosine with warmup (3%)
%     [TODO: Chèn Bảng - Hyperparameter Table cho 3 models × 3 phases]
%
% 4.2 Phase 1: Supervised Fine-Tuning - Basic Payloads
%   4.2.1 Training objective
%     - Dataset: phase1_balanced_10k.jsonl (10,000 samples)
%     - Mục tiêu: Học syntax của payload attacks
%     - Loss function: Cross-entropy trên next-token prediction
%   4.2.2 Training configuration
%     - Input format: Instruction-following (ChatML style)
%     - Target: Assistant responses (payloads only)
%     - Masking: User messages không tính loss
%   4.2.3 Expected outcomes
%     - Model học được:
%       * Valid attack syntax (SQLi, XSS, Command Injection)
%       * Basic obfuscation patterns
%       * Encoding techniques
%     - Chưa học được: WAF-specific bypass strategies
%
% 4.3 Phase 2: Supervised Fine-Tuning - Observation-Enhanced
%   4.3.1 Training objective
%     - Dataset: phase2_with_replay_24k.jsonl (24,000 samples)
%     - Mục tiêu: Học từ BLOCKED/PASSED observations
%     - Continue training: Load Phase 1 adapter
%   4.3.2 Incremental learning strategy
%     - Replay buffer (4k Phase 1 samples) tránh forgetting
%     - 20k observations mới với context
%     - Lower learning rate để ổn định
%   4.3.3 Expected outcomes
%     - Model học được:
%       * Nhận biết patterns bị WAF chặn
%       * Sử dụng PASSED examples làm template
%       * Refine obfuscation strategy theo WAF behavior
%
% 4.4 Phase 3: Reinforcement Learning - Live WAF Interaction
%   4.4.1 RL Framework
%     - Algorithm: REINFORCE (policy gradient)
%     - Environment: ModSecurity PL1 + DVWA (Docker)
%     - State: Attack context (technique, target, history)
%     - Action: Generated payload (string)
%     - Reward design:
%       * r = +1 if WAF bypass (status != 403)
%       * r = +2 if successful exploit (SQLi result visible, XSS executes)
%       * r = 0 if blocked
%   4.4.2 Training loop
%     - Episode-based training (150-200 episodes)
%     - Mỗi episode: 50-100 attack attempts
%     - Update policy sau mỗi episode
%     - Gradient computation: Policy gradient với baseline
%   4.4.3 Safety constraints
%     - CHỈ train trên ModSecurity PL1
%     - PL4 và Coraza chỉ dùng cho evaluation
%     - Không train trên production systems
%   4.4.4 Expected outcomes
%     - Model học được:
%       * Adapt to specific WAF configuration
%       * Maximize bypass success rate
%       * Discover novel evasion patterns
%
% 4.5 Phân tích Training Loss (PLACEHOLDER - CHƯA CÓ DỮ LIỆU)
%   4.5.1 Phase 1 Loss Curves
%     - [PLACEHOLDER] Training loss convergence
%     - [PLACEHOLDER] Validation loss
%     - [PLACEHOLDER] So sánh 3 models (Gemma, Phi-3, Qwen)
%     [TODO: Chèn Hình - Phase 1 loss curves khi có data]
%   4.5.2 Phase 2 Loss Curves
%     - [PLACEHOLDER] Continual learning stability
%     - [PLACEHOLDER] Catastrophic forgetting analysis
%     - [PLACEHOLDER] Observation impact on loss
%     [TODO: Chèn Hình - Phase 2 loss curves khi có data]
%   4.5.3 Phase 3 Reward Curves
%     - [PLACEHOLDER] Episode rewards over time
%     - [PLACEHOLDER] Success rate improvement
%     - [PLACEHOLDER] Exploration vs exploitation
%     [TODO: Chèn Hình - Phase 3 reward curves khi có data]
%   4.5.4 Model Comparison
%     - [PLACEHOLDER] Convergence speed: Gemma vs Phi-3 vs Qwen
%     - [PLACEHOLDER] Final loss values
%     - [PLACEHOLDER] Overfitting analysis
%
% 4.6 Kết quả đánh giá (PLACEHOLDER - CHƯA CÓ DỮ LIỆU)
%   4.6.1 Baseline Comparison
%     - [PLACEHOLDER] Pretrained models (zero-shot)
%     - [PLACEHOLDER] Phase 1 models
%     - [PLACEHOLDER] Phase 2 models
%     - [PLACEHOLDER] Phase 3 models (RL-enhanced)
%   4.6.2 Pass Rate Analysis
%     - [PLACEHOLDER] ModSecurity PL1:
%       * Gemma 2 2B: X%
%       * Phi-3 Mini: Y%
%       * Qwen 2.5 3B: Z%
%     - [PLACEHOLDER] ModSecurity PL4:
%       * Gemma 2 2B: A%
%       * Phi-3 Mini: B%
%       * Qwen 2.5 3B: C%
%     - [PLACEHOLDER] Coraza:
%       * Cross-WAF generalization
%     [TODO: Chèn Bảng - Pass Rate Matrix]
%   4.6.3 Success Rate Analysis
%     - [PLACEHOLDER] Bypass + Exploit success
%     - [PLACEHOLDER] Attack type breakdown (SQLi, XSS, OS)
%     [TODO: Chèn Bảng - Success Rate Matrix]
%   4.6.4 Payload Quality Analysis
%     - [PLACEHOLDER] Diversity metrics
%     - [PLACEHOLDER] Payload complexity
%     - [PLACEHOLDER] Obfuscation patterns learned
%
% 4.7 Phân tích định tính (PLACEHOLDER - CHƯA CÓ DỮ LIỆU)
%   4.7.1 Case Studies
%     - [PLACEHOLDER] Ví dụ payload thành công
%     - [PLACEHOLDER] Phân tích obfuscation strategy
%     - [PLACEHOLDER] So sánh giữa models
%   4.7.2 Failure Analysis
%     - [PLACEHOLDER] Payload bị chặn
%     - [PLACEHOLDER] Nguyên nhân thất bại
%     - [PLACEHOLDER] Limitations của approach
%   4.7.3 Novel Patterns Discovered
%     - [PLACEHOLDER] RL discovered new evasion techniques
%     - [PLACEHOLDER] Unexpected bypass strategies
%
% YÊU CẦU OUTPUT:
% 1. Viết HOÀN TOÀN BẰNG TIẾNG VIỆT
% 2. Phần 4.1-4.4: Viết đầy đủ lý thuyết và kế hoạch
% 3. Phần 4.5-4.7: Viết structure + [PLACEHOLDER] notes
% 4. Dùng LaTeX format với \subsection, \subsubsection
% 5. Chèn code config examples
% 6. Tạo bảng hyperparameters
% 7. Giải thích rõ RL reward design
% 8. Độ dài: 12-15 trang (bao gồm placeholders)
%
% CONFIG FILES REFERENCE:
% - configs/remote_gemma2_2b_phase1.yaml
% - configs/remote_phi3_mini_phase1.yaml
% - configs/remote_qwen_3b_phase1.yaml
% - (Similar for phase2 and phase3_rl)
%
% LƯU Ý QUAN TRỌNG:
% - Phần lý thuyết (4.1-4.4) phải HOÀN CHỈNH và CHI TIẾT
% - Phần results (4.5-4.7) chỉ viết structure với [PLACEHOLDER]
% - Khi có training results, sẽ điền vào placeholders
% - Giải thích RÕ RÀNG tại sao cần 3 phases
% - Nhấn mạnh RL chỉ train trên PL1, PL4/Coraza chỉ eval
% - Trích dẫn hyperparameters từ config files
% - Khi viết phần synthetic generative data (Phase 2 dataset), chèn citation về quy trình tạo dữ liệu tổng hợp cho LLM fine-tuning, ví dụ \cite{selfinstruct2023,magister2024synthetic} (thêm các key này vào references.bib).
% ========================================

\section*{Lời cảm ơn (tạm thời)}
Chúng em xin cảm ơn thầy TS. Nguyễn An Khương và anh Trần Lê Quốc Khánh B.Eng đã tận tình hướng dẫn; đồng thời cảm ơn anh Đoàn Thế Anh, anh Nguyễn Bá Nhật Quang, anh Nguyễn Anh Kiệt đã hỗ trợ trong quá trình thực hiện đồ án này.

\section{Quy trình huấn luyện và đánh giá}
\label{sec:training}

% TODO: Agent writes subsections 4.1 - 4.7 following the prompt above
% This section should be approximately 12-15 pages covering:
% - Complete training pipeline (Phases 1-3)
% - Hyperparameter configurations
% - RL framework and reward design
% - Placeholder sections for loss analysis and evaluation results
% - Structure ready for filling in data after remote training completes


% =========================================================
% SECTION 5: CONCLUSION & LIMITATIONS
% =========================================================

\section{Kết luận và hạn chế}
\label{sec:conclusion}

\subsection{Kết luận}
% TODO: Tóm tắt contributions khi có đầy đủ kết quả
% - Xây dựng thành công Red Agent pipeline
% - Dataset với 509-532 techniques
% - So sánh 3 models (Gemma, Phi-3, Qwen)
% - Áp dụng thành công RL trên WAF

\subsection{Hạn chế}
% - Tài nguyên phần cứng hạn chế (16GB VRAM)
% - Số lượng WAF profiles hạn chế
% - Chỉ test trên DVWA (1 ứng dụng)
% - Thời gian training bị giới hạn

\subsection{Hướng phát triển}
% - Mở rộng sang nhiều WAF và applications
% - Thêm attack types (SSRF, XXE, ...)
% - Phát triển Blue Agent (defensive side)
% - Kết hợp constraint decoding

\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
