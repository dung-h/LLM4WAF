\section{Xây dựng Dataset}
\label{sec:data_setup}

\subsection{Tổng quan phương pháp}
Dataset huấn luyện được xây dựng theo quy trình hai giai đoạn: \textbf{Phase 1} sinh tập baseline thông qua LLM thương mại và chỉ giữ lại các payload thành công (PASSED), và \textbf{Phase 2} mở rộng dataset bằng cơ chế observation-based refinement với context từ kết quả WAF testing. Tất cả training samples đều là payload PASSED trên ModSecurity PL1 - đây là điều kiện quan trọng để đảm bảo mô hình học các patterns bypass hiệu quả.

\subsubsection{Lựa chọn LLM sinh dữ liệu}
Nghiên cứu này sử dụng hai LLM thương mại để sinh payload candidates:
\begin{itemize}
    \item \textbf{Deepseek V2.5:} Mô hình mã nguồn mở với khả năng reasoning mạnh, chi phí API thấp (0.14 USD/1M tokens).
    \item \textbf{Google Gemini 2.0 Flash:} Mô hình tốc độ cao với hiểu biết tốt về web security, hỗ trợ context dài (1M tokens).
\end{itemize}

Việc sử dụng LLM thương mại để sinh dữ liệu tổng hợp mang lại ba lợi thế:

\textbf{(1) Scalability và Technique Coverage:} LLM có thể sinh hàng nghìn payload trong thời gian ngắn cho 509 kỹ thuật bypass từ knowledge base. Trong khi thu thập thủ công từ CVE databases thường chỉ có vài trăm mẫu và bị bias về các kỹ thuật phổ biến, phương pháp tổng hợp cho phép phân bố cân bằng giữa SQLI, XSS, OS\_INJECTION.

\textbf{(2) Quality Control qua WAF Validation:} Mỗi payload sinh ra được test ngay trên ModSecurity PL1. Chỉ những payload PASSED mới được đưa vào training set, đảm bảo 100\% dữ liệu huấn luyện là khả thi và cập nhật.

\textbf{(3) RAG-Augmented Generation:} LLM được augment với knowledge base chứa 500+ writeups từ chuyên gia bảo mật. Khi sinh payload, retrieval system tìm kiếm documents liên quan và inject vào prompt, giúp LLM học patterns phức tạp từ ví dụ thực tế.

\subsection{Phase 1: Initial Dataset Generation}
\label{subsec:phase1_data}

Phase 1 tập trung vào việc xây dựng tập baseline với độ phủ kỹ thuật rộng. Quy trình gồm 4 bước tuần tự: generation, testing, filtering, và construction.

\subsubsection{Bước 1: LLM Generation}

Với mỗi kỹ thuật trong knowledge base (509 kỹ thuật), hệ thống tạo prompt theo template sau:

\begin{lstlisting}[language=Python, basicstyle=\small\ttfamily, breaklines=true, frame=single]
Generate WAF-evasion payloads.

Target: {attack_type} on ModSecurity PL1.
Technique: {technique}

IMPORTANT: Generate ONLY the payload code. Do not provide explanations, ask questions, or start conversations.
\end{lstlisting}

Trong đó:
\begin{itemize}
    \item \texttt{attack\_type}: Loại tấn công (SQLI, XSS, OS\_INJECTION)
    \item \texttt{technique}: Tên kỹ thuật cụ thể (vd: "Double URL Encode", "SQL UPDATEXML Error-based")
\end{itemize}

LLM (Deepseek/Gemini) sinh ra payload candidate dựa trên mô tả kỹ thuật. \textbf{Ví dụ cụ thể:}
\begin{itemize}
    \item \textbf{Input:} SQLI + Double URL Encode
    \item \textbf{LLM Output:} \texttt{\%2527\%2520OR\%25201\%253D1--}
    \item \textbf{Giải thích:} Single quote (\texttt{'}) được encode thành \texttt{\%27}, sau đó encode lần 2 thành \texttt{\%2527}
\end{itemize}

\subsubsection{Bước 2: WAF Testing}

Mỗi payload được gửi đến ModSecurity PL1 environment qua HTTP request. WAF engine phân tích request và trả về một trong hai trạng thái:
\begin{itemize}
    \item \textbf{PASSED:} Request không kích hoạt bất kỳ WAF rule nào, được phép qua
    \item \textbf{BLOCKED:} Request kích hoạt ít nhất một ModSecurity rule, bị chặn với HTTP 403
\end{itemize}

ModSecurity PL1 (Paranoia Level 1) là cấu hình cơ bản của OWASP Core Rule Set, chứa các rules phổ biến nhất cho SQLI, XSS, và command injection. Đây là target môi trường cho Phase 1.

\subsubsection{Bước 3: Filtering - Chỉ giữ PASSED}

\textbf{Chỉ những payload PASSED được giữ lại làm training samples}. Đây là điểm quan trọng nhất trong thiết kế dataset:

\begin{itemize}
    \item Dataset huấn luyện chỉ chứa các payload thành công bypass ModSecurity PL1
    \item Payload BLOCKED bị loại bỏ hoàn toàn khỏi training set
    \item Tỷ lệ PASSED trong Phase 1: 38\% (3,800/10,000 candidates)
\end{itemize}

\textbf{Lý do thiết kế này:} Mục tiêu của mô hình là học cách sinh payload có khả năng bypass cao. Nếu huấn luyện trên cả BLOCKED payloads, mô hình có thể học các patterns không hiệu quả hoặc bị WAF detect dễ dàng. Việc chỉ sử dụng PASSED samples đảm bảo mô hình tối ưu hóa theo hướng "what works" thay vì học cả "what doesn't work".

\subsubsection{Bước 4: Dataset Construction}

Payload PASSED được chuyển đổi sang instruction-following format tương thích với LLM training:

\begin{lstlisting}[language=json, basicstyle=\small\ttfamily, breaklines=true, frame=single]
{
  "messages": [
    {
      "role": "user",
      "content": "Generate WAF-evasion payloads.\n\nTarget: SQLI on ModSecurity PL1.\nTechnique: Double URL Encode\n\nIMPORTANT: Generate ONLY the payload code..."
    },
    {
      "role": "assistant",
      "content": "%2527%2520OR%25201%253D1--"
    }
  ],
  "attack_type": "SQLI",
  "technique": "obf_double_url_encode",
  "result": "passed"
}
\end{lstlisting}

\subsubsection{Kết quả Phase 1}

Sau quy trình trên, Phase 1 thu được:
\begin{itemize}
    \item \textbf{10,000 training samples} (tất cả PASSED trên ModSecurity PL1)
    \item \textbf{509 kỹ thuật} được phủ, phân bố cân bằng:
    \begin{itemize}
        \item SQLI: 3,400 samples (34\%)
        \item XSS: 3,300 samples (33\%)
        \item OS\_INJECTION: 3,300 samples (33\%)
    \end{itemize}
    \item \textbf{Tỷ lệ PASSED từ candidates:} 38\% (10,000 PASSED / 26,000 generated)
    \item \textbf{Technique diversity:} Mỗi kỹ thuật có trung bình 19.6 samples
\end{itemize}

Dataset Phase 1 được lưu dưới format JSONL tương thích với các framework huấn luyện LLM (Unsloth, TRL, Axolotl).

\subsection{Sinh dữ liệu bằng LLM cho fine-tuning: cơ sở và cách áp dụng}
\label{subsec:llm_synthetic_data}
\subsubsection{Bối cảnh và mục tiêu nghiên cứu}
Một hướng phổ biến trong huấn luyện LLM theo nhiệm vụ là sinh dữ liệu tổng hợp bằng chính LLM, sau đó lọc và tinh chỉnh (bootstrapping). Self-Instruct là phương pháp tiêu biểu: bắt đầu từ một tập seed instruction nhỏ, dùng mô hình sinh instruction mới và câu trả lời, lọc chất lượng rồi mở rộng dữ liệu \cite{selfinstruct2023}. Alpaca cho thấy khi kết hợp dữ liệu chỉ dẫn tổng hợp và quy trình tinh chỉnh phù hợp, có thể tạo mô hình tuân thủ chỉ dẫn ở chi phí thấp hơn \cite{alpaca2023}.

Trong miền an ninh, nhiều công trình gần đây khảo sát việc dùng LLM để tạo dữ liệu kiểm thử và phân tích tương tác với cơ chế phòng vệ, như đánh giá WAF theo các kịch bản khác nhau hoặc tạo mẫu kiểm thử tổng hợp \cite{waf-evasion-survey,gensqli2024,genxss2025,cyberllminstruct2025,techscience_synthetic_payloads,isj_rl_evasive}.

\subsubsection{Điều chỉnh cho mục tiêu đo lường và tính tái lập}
Trong đồ án, dữ liệu tổng hợp không được dùng như “mẫu thao tác”, mà được thiết kế như \textbf{mẫu kiểm thử có cấu trúc} cho mục tiêu đo lường:
\begin{itemize}
  \item Instruction tập trung vào \textbf{định dạng}, \textbf{ràng buộc} và \textbf{ngữ cảnh môi trường} (WAF/app/config), để mô hình học tuân thủ và tương tác nhất quán.
  \item Phần nội dung nhạy cảm (nếu có trong nhiệm vụ) được \textbf{giản lược} trong báo cáo; trong dữ liệu thực nghiệm, hệ thống áp dụng bộ lọc và kiểm tra hợp lệ để loại các mẫu không phù hợp.
  \item Mọi mẫu đều gắn nhãn và metadata để phục vụ phân tích lỗi và tái lập thí nghiệm.
\end{itemize}

\subsubsection{Quy trình Self-Instruct (rút gọn) dùng trong đồ án}
Đồ án áp dụng quy trình lấy cảm hứng từ Self-Instruct \cite{selfinstruct2023} theo các bước:
\begin{enumerate}
  \item \textbf{Seed tasks}: xây dựng tập nhiệm vụ seed có phủ đủ nhóm (SQLi/XSS/CMDI ở mức phân loại), kèm ràng buộc định dạng.
  \item \textbf{Generate}: dùng mô hình nền sinh thêm instruction và output theo template.
  \item \textbf{Filter}: lọc theo tiêu chí hợp lệ (parse được, đủ trường, không trùng lặp, không mâu thuẫn).
  \item \textbf{Deduplicate}: loại trùng theo fingerprint/embedding hoặc theo luật đơn giản (hash normalized).
  \item \textbf{Curate}: chọn mẫu đại diện, cân bằng lớp và kiểm tra thủ công một phần.
  \item \textbf{Assemble}: ghép thành dataset Phase 1/Phase 2.
\end{enumerate}
Quy trình này nhằm tăng độ phủ và giảm lỗi định dạng, đồng thời giữ dữ liệu đủ “sạch” để mô hình học hành vi ổn định.

\subsection{Định dạng dữ liệu (schema) và kiểm tra hợp lệ}
\label{subsec:data_schema}
Để tự động hóa đo lường, mỗi mẫu huấn luyện trong Phase 1/2 được chuẩn hóa theo schema. Tối thiểu gồm:
\begin{itemize}
  \item \textbf{task\_id}, \textbf{task\_type}
  \item \textbf{context}: mô tả endpoint, tham số, mục tiêu đo lường, cấu hình WAF, giới hạn độ dài.
  \item \textbf{constraints}: quy tắc định dạng đầu ra (ví dụ JSON), trường bắt buộc, quy tắc dừng sinh.
  \item \textbf{assistant\_output}: đầu ra mong muốn/được gợi ý theo template.
  \item \textbf{label}: valid/invalid và lý do.
  \item \textbf{observation} (Phase 2): tín hiệu phản hồi môi trường đã chuẩn hóa.
\end{itemize}
Điểm mấu chốt là schema phải \textbf{dễ parse} và \textbf{ổn định} giữa các họ mô hình, đặc biệt khi tokenizer và chat template khác nhau (Section \ref{sec:models}).

\begin{table}[H]
\centering
\caption{Ví dụ schema dữ liệu ở mức minh họa}
\label{tab:data_schema_example}
\begin{tabularx}{\textwidth}{@{}lX@{}}
\toprule
\textbf{Trường} & \textbf{Giải thích} \\
\midrule
task\_type & Nhóm nhiệm vụ (\texttt{SQLI}/\texttt{XSS}/\texttt{CMDI}) \\
context & Mục tiêu, ràng buộc môi trường, cấu hình WAF, yêu cầu đánh giá \\
constraints & Định dạng JSON, trường bắt buộc, độ dài tối đa, stop tokens \\
assistant\_output & Đầu ra theo template, phục vụ parse/đo lường \\
observation & Trạng thái WAF, mã phản hồi, nhãn hợp lệ (đã chuẩn hóa) \\
\bottomrule
\end{tabularx}
\end{table}

\subsubsection{Dữ liệu huấn luyện theo định dạng chat (JSONL)}
\label{subsec:jsonl_chat_format}
Đồ án lưu dữ liệu huấn luyện SFT ở dạng JSONL, trong đó mỗi dòng tương ứng một mẫu \texttt{messages} theo quy ước hội thoại (role/content). Cách biểu diễn này có hai lợi ích: (i) tương thích trực tiếp với nhiều thư viện fine-tuning (instruction tuning), và (ii) dễ mở rộng sang Phase 2 bằng cách đưa \texttt{observation} vào ngữ cảnh.

\paragraph{Ví dụ schema Phase 1 với prompt template thực tế.}
\begin{lstlisting}[basicstyle=\small\ttfamily, breaklines=true, frame=single]
{
  "messages": [
    {"role": "user",
     "content": "Generate WAF-evasion payloads.\n\nTarget: SQLI on ModSecurity PL1.\nTechnique: Double URL Encode\n\nIMPORTANT: Generate ONLY the payload code."},
    {"role": "assistant",
     "content": "%2527%2520OR%25201%253D1--"}
  ],
  "attack_type": "SQLI",
  "technique": "obf_double_url_encode",
  "result": "passed"
}
\end{lstlisting}
Prompt template đơn giản, chỉ chứa loại tấn công, kỹ thuật cụ thể, và ràng buộc định dạng. LLM được yêu cầu sinh ONLY payload code để tránh verbose explanations.

\paragraph{Ví dụ schema Phase 2 với \texttt{observation}.}
\begin{lstlisting}[basicstyle=\small\ttfamily, breaklines=true, frame=single]
{
  "messages": [
    {"role": "user",
     "content": "Generate WAF-evasion payloads.\n\nTarget: XSS on ModSecurity PL1.\nTechnique: XSS Body onload\n\n[Observations]\n- BLOCKED: [\"<body onload=alert(1)>\", ...]\n- PASSED: [\"%253Cbody%2520onload%253Dalert...\", \"%253CbOdY%2520ONLOAd%253D...\"]\n\nInstruction: Generate NEW payload learning from PASSED examples."},
    {"role": "assistant",
     "content": "%253CbOdy%2520ONLoad%253DALERt%25281%2529%253E"}
  ],
  "relabeled": true,
  "observation": {
    "waf_status": "<allowed|blocked>",
    "http_status": 403
  }
}
\end{lstlisting}

\subsubsection{Format request tới LLM API để sinh dữ liệu (minh họa)}
\label{subsec:prompt_request_format}
Khi sinh dữ liệu tổng hợp, evaluator/driver gọi LLM theo dạng \emph{chat completion} với \texttt{messages} (system/user) và các tham số điều khiển (temperature, max tokens, stop). Hình thức request (minh họa, đã ẩn nội dung) như sau:
\begin{verbatim}
{
  "model": "<MODEL_NAME>",
  "messages": [
    {"role": "system", "content": "<SYSTEM INSTRUCTIONS>"},
    {"role": "user", "content": "<TASK CONTEXT + CONSTRAINTS + OPTIONAL OBSERVATIONS>"}
  ],
  "temperature": 0.2,
  "max_tokens": 256,
  "stop": ["<STOP_TOKEN_1>", "<STOP_TOKEN_2>"]
}
\end{verbatim}
Điểm quan trọng là \textbf{constraints phải đi kèm request} (schema, giới hạn độ dài, quy tắc dừng) để giảm \texttt{invalid} và hạn chế runaway generation. Với Phase 2, phần \texttt{observations} được đưa vào \texttt{user.content} để mô hình học mối quan hệ ngữ cảnh--kết quả theo đúng thiết kế của pipeline (Section \ref{subsec:phase2_data}).

\subsection{Phase 1: dữ liệu SFT nền tảng}
\label{subsec:phase1_data}
\subsubsection{Mục tiêu}
Phase 1 tập trung vào việc giúp mô hình:
\begin{itemize}
  \item Nhận đúng vai trò hội thoại (system/user/assistant).
  \item Sinh đầu ra có cấu trúc ổn định theo schema.
  \item Giảm tỷ lệ invalid do sai định dạng hoặc trả lời rỗng/lạc đề.
\end{itemize}

\subsubsection{Thiết kế tập seed và cân bằng lớp}
Tập seed được thiết kế để cân bằng theo \texttt{task\_type}, đồng thời đa dạng hóa theo bề mặt HTTP (query/body/header) và theo ràng buộc (độ dài, trường bắt buộc). Mục đích là tránh việc mô hình “học mẹo” theo một template cố định và suy giảm khi đổi ngữ cảnh.

\subsubsection{Chất lượng dữ liệu và vòng lặp làm sạch}
Các tiêu chí lọc chính:
\begin{itemize}
  \item Parse được (ví dụ JSON hợp lệ).
  \item Có đủ trường bắt buộc; không có trường thừa gây nhiễu parser.
  \item Nhất quán giữa context--constraints--output (không mâu thuẫn).
  \item Tránh trùng lặp nặng (duplicate template).
\end{itemize}
Các lỗi định dạng được coi là lỗi “cơ sở” và cần được giải quyết trước khi chuyển sang Phase 2/3.

\subsubsection{Thống kê mô tả và minh họa}
Trong Phase 1, đồ án thu được tập dữ liệu đầy đủ khoảng 39{,}155 mẫu và trích một tập con cân bằng 10{,}000 mẫu để fine-tuning nhằm phù hợp giới hạn tài nguyên, đồng thời vẫn giữ nguyên độ phủ 509 kỹ thuật (technique coverage 100\%). Trên tập cân bằng 10k, phân bố theo nhóm nhiệm vụ là SQLI 47.52\%, XSS 52.00\%, và OS\_INJECTION 0.48\%. Thống kê độ dài cho thấy mean khoảng 105 ký tự và median 76 ký tự; đây là cơ sở để đặt giới hạn độ dài và quy tắc dừng sinh (Section \ref{subsec:experiment_setup}).

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/attack_type_phase1.png}
\caption{Phân bố nhóm nhiệm vụ ở Phase 1 (tập cân bằng 10k)}
\label{fig:attack_type_phase1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figures/payload_length_phase1.png}
\caption{Phân bố độ dài chuỗi ở Phase 1 (tập cân bằng 10k)}
\label{fig:payload_length_phase1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figures/technique_dist_phase1.png}
\caption{Phân bố technique ở Phase 1 (tập cân bằng 10k)}
\label{fig:technique_dist_phase1}
\end{figure}

\subsection{Phase 2: dữ liệu có quan sát từ môi trường}
\label{subsec:phase2_data}
\subsubsection{Mục tiêu}
Phase 2 đưa tín hiệu phản hồi môi trường vào dữ liệu huấn luyện để mô hình học mối quan hệ giữa \textbf{ngữ cảnh} và \textbf{kết quả đo lường}. Nếu Phase 1 trả lời câu hỏi “mô hình biết phản hồi theo format hay chưa”, Phase 2 trả lời câu hỏi “mô hình có học được quy luật tương tác của môi trường trong phạm vi thí nghiệm hay chưa”.

\subsubsection{Thu thập quan sát và chuẩn hóa}
Mỗi lần chạy đánh giá, evaluator ghi nhận các trường tối thiểu:
\begin{itemize}
  \item Trạng thái allow/blocked suy luận từ WAF hoặc mã phản hồi.
  \item HTTP status code và một số metadata ổn định.
  \item Nhãn valid/invalid của đầu ra mô hình.
\end{itemize}
Quan sát được chuẩn hóa thành trường \texttt{observation} để có thể dùng lại trong huấn luyện.

\subsubsection{Tạo dữ liệu huấn luyện từ quan sát}

Phase 2 áp dụng workflow tương tự Phase 1 nhưng có bổ sung observations vào prompt:

\textbf{Bước 1: Observation Retrieval} - Với mỗi kỹ thuật, hệ thống lấy 2-4 payload BLOCKED và 2-4 payload PASSED từ Phase 1 testing results. Nếu kỹ thuật mới chưa có PASSED examples, chỉ đưa BLOCKED examples.

\textbf{Bước 2: LLM Generation with Context} - Prompt template bao gồm observations section như đã minh họa ở Section \ref{subsec:jsonl_chat_format}. LLM học từ PASSED patterns để sinh payload tương tự và tránh BLOCKED patterns.

\textbf{Bước 3: WAF Testing} - Test payload mới trên ModSecurity PL1, nhận kết quả PASSED hoặc BLOCKED.

\textbf{Bước 4: Filtering} - \textbf{Chỉ giữ PASSED payloads} (giống Phase 1). Tỷ lệ PASSED trong Phase 2 cải thiện lên 52\% (so với 38\% ở Phase 1) nhờ LLM học từ observations.

\textbf{Bước 5: Dataset Construction + Replay Buffer:}
\begin{itemize}
  \item 20,000 samples mới từ Phase 2 generation (532 kỹ thuật, bao gồm 23 kỹ thuật mới)
  \item 4,000 samples replay từ Phase 1 để giảm catastrophic forgetting
  \item \textbf{Tổng: 24,000 training samples}
\end{itemize}

\textbf{Ví dụ cải thiện từ observations:} Với kỹ thuật "XSS Body onload", Phase 1 có 2 BLOCKED và 2 PASSED examples. Khi đưa vào observations, LLM sinh payload mới {\small\texttt{\%253CbOdy\%2520ONLoad\%253DALERt\%25281\%2529\%253E}} kết hợp case mixing và double URL encoding từ PASSED patterns, thành công bypass ModSecurity PL1.

Đây là bước "cầu nối" giúp RL ổn định hơn: mô hình bước vào Phase 3 với tỷ lệ valid cao (>95\%), hiểu sơ bộ cấu trúc phản hồi môi trường, và có độ phủ kỹ thuật rộng hơn (+4.5\%).

% \subsubsection{Ví dụ payload đại diện từ dataset}
% Bảng payload examples tạm thời bỏ để tránh lỗi compile

% \begin{table}[H]
% \caption{Ví dụ payload được LLM sinh ra trong dataset huấn luyện}
% \label{tab:dataset_payload_examples}
% ...payload examples...
% \end{table}

% Các payload minh họa khả năng: Multi-layer encoding, Case mixing, Comment injection, Whitespace obfuscation, Unicode encoding, SQL functions.

\subsubsection{Thống kê mô tả và minh họa}
Phase 2 gồm hai nguồn dữ liệu: (i) 20{,}000 mẫu từ quan sát mới và (ii) 4{,}000 mẫu replay buffer (relabeled) nhằm giảm catastrophic forgetting. Tổng cộng Phase 2 có 24{,}000 mẫu và 532 kỹ thuật; phân bố nhóm nhiệm vụ dịch chuyển theo quan sát, với SQLI chiếm khoảng 55.28\%, XSS 37.05\% và OS\_INJECTION 7.67\%. Các hình \ref{fig:attack_type_phase2}--\ref{fig:technique_dist_phase2} minh họa phân bố lớp, độ dài, và độ phủ kỹ thuật của Phase 2.

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{figures/attack_type_phase2.png}
\caption{Phân bố nhóm nhiệm vụ ở Phase 2}
\label{fig:attack_type_phase2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{figures/payload_length_phase2.png}
\caption{Phân bố độ dài chuỗi ở Phase 2}
\label{fig:payload_length_phase2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/technique_dist_phase2.png}
\caption{Phân bố technique ở Phase 2}
\label{fig:technique_dist_phase2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{figures/quality_metrics.png}
\caption{Chỉ số chất lượng dữ liệu tổng hợp (diversity/validity/complexity) ở Phase 1 và Phase 2}
\label{fig:quality_metrics}
\end{figure}

\subsection{Thiết lập thực nghiệm}
\label{subsec:experiment_setup}
\subsubsection{Triển khai bằng Docker Compose}
Môi trường được triển khai bằng Docker Compose \cite{docker} nhằm dễ tái lập và cô lập phụ thuộc. Các thành phần chính:
\begin{itemize}
  \item \textbf{DVWA}: ứng dụng mục tiêu \cite{dvwa}.
  \item \textbf{WAF}: ModSecurity với OWASP CRS \cite{modsecurity,owaspCRS} và Coraza \cite{coraza}.
  \item \textbf{Evaluator/Driver}: điều phối request, thu thập phản hồi, ghi log và tính chỉ số.
  \item \textbf{Logging}: lưu audit log WAF và log evaluator để phân tích.
\end{itemize}

% Bỏ sơ đồ Docker Compose (không đủ chỗ trong báo cáo).
\paragraph{Ghi chú triển khai.}
Môi trường thực nghiệm được triển khai bằng Docker Compose trên network \texttt{waf-network}. Evaluator/driver gửi HTTP requests tới endpoint của WAF (ModSecurity CRS ở các mức PL và Coraza CRS), WAF đóng vai trò reverse proxy và định tuyến theo path (\texttt{/dvwa}, \texttt{/juice}) tới backend tương ứng. Log phục vụ phân tích gồm audit log phía WAF và log của evaluator (trạng thái allow/blocked, mã HTTP, nhãn valid/invalid, và metadata ổn định).

\subsubsection{Cấu hình WAF và kịch bản đánh giá}
ModSecurity + OWASP CRS là môi trường chính \cite{modsecurity,owaspCRS}. Việc chọn Paranoia Level cho phép tạo “khoảng cách cấu hình” giữa môi trường huấn luyện và môi trường đánh giá, phục vụ kiểm tra tổng quát hóa. Coraza được dùng cho đánh giá chuyển giao cross-WAF \cite{coraza}.

\subsubsection{Tiêu chí hợp lệ và quy tắc dừng sinh}
Để tự động hóa, đầu ra được phân loại:
\begin{itemize}
  \item \textbf{Valid}: tuân thủ schema, parse được, đủ trường bắt buộc.
  \item \textbf{Invalid}: sai định dạng, thiếu trường, rỗng hoặc từ chối.
\end{itemize}
Quy tắc dừng sinh (stop tokens, max tokens, eos) được thiết lập theo từng tokenizer/chat template (Section \ref{subsec:tokenizer_analysis}) để giảm lỗi do sinh quá dài hoặc chứa marker ngoài dự kiến.

\subsection{Thiết lập tái lập và ghi nhận thực nghiệm}
\label{subsec:reproducibility_logging}
\subsubsection{Tái lập (reproducibility) trong đồ án có nghĩa là gì?}
Trong đồ án, “tái lập” nghĩa là có thể chạy lại cùng pipeline với cùng cấu hình và thu được kết quả gần tương đương trong sai số chấp nhận được. Điều này bao gồm:
\begin{itemize}
  \item Lưu cấu hình (hyperparameters, seed, phiên bản container, cấu hình WAF).
  \item Ghi log theo schema thống nhất để phân tích lại.
  \item Cố định các yếu tố dễ gây sai lệch (template prompt, stop tokens, preprocessing).
\end{itemize}
Do môi trường có yếu tố nhiễu (hạ tầng, network, scheduler), tái lập được hiểu theo nghĩa thống kê: kết quả ổn định trên nhiều lần chạy/seed.

\subsubsection{Logging tối thiểu}
Đồ án khuyến nghị logging tối thiểu cho mỗi mẫu: \texttt{model}, \texttt{phase}, \texttt{seed}, \texttt{waf\_config}, \texttt{valid/invalid}, \texttt{blocked/allowed}, \texttt{http\_status}, và ghi chú phục vụ phân tích lỗi.
