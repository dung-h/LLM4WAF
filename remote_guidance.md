# H∆∞·ªõng D·∫´n Train Remote: Phase 1-2-3 C≈© (Scale Up 7B/14B)

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n t√°i t·∫°o quy tr√¨nh training c≈© (SFT -> Reasoning -> RL) tr√™n c√°c model l·ªõn h∆°n ƒë·ªÉ ki·ªÉm ch·ª©ng hi·ªáu nƒÉng.

## 1. Chi·∫øn L∆∞·ª£c D·ªØ Li·ªáu & Model

*   **Dataset:** Khuy√™n d√πng **`data/processed/red_phase1_enriched_v2.jsonl`** (~42k samples). ƒê√¢y l√† b·∫£n ƒë√£ ƒë∆∞·ª£c l√†m gi√†u, c√¢n b·∫±ng l·∫°i t·ªâ l·ªá SQLi/XSS/OS_Injection v√† b·ªï sung c√°c k·ªπ thu·∫≠t n√© tr√°nh ph·ª©c t·∫°p.
*   **Model Size:**
    *   **7B/8B:** C√¢n b·∫±ng t·ªët gi·ªØa hi·ªáu nƒÉng v√† t·ªëc ƒë·ªô.
    *   **14B:** Kh·∫£ nƒÉng h·ªçc reasoning v√† generalize t·ªët nh·∫•t, nh∆∞ng c·∫ßn VRAM 24GB+.

## 2. Chu·∫©n B·ªã D·ªØ Li·ªáu (Local -> Remote)

N√©n v√† upload c√°c file sau l√™n server:
1.  `data/processed/red_phase1_enriched_v2.jsonl` (Phase 1 SFT - **B·∫£n Enriched**)
2.  `data/processed/red_v40_phase2_reasoning.jsonl` (Phase 2 Reasoning c≈©)
3.  Codebase: To√†n b·ªô th∆∞ m·ª•c `scripts/` (ƒë·∫∑c bi·ªát `scripts/train_red.py`), `rl/`, `configs/`.

## 3. Script Training T·ª± ƒê·ªông (One-Click)

T·∫°o file `run_remote_optimized.sh` tr√™n server:

```bash
#!/bin/bash

# --- CONFIGURATION ---
# MODEL_NAME="Qwen/Qwen2.5-7B-Instruct"
# MODEL_NAME="meta-llama/Meta-Llama-3-8B-Instruct"
MODEL_NAME="Qwen/Qwen2.5-14B-Instruct" 

# Hugging Face Token
export HF_TOKEN="hf_..."

# Data Paths (L∆∞u √Ω: D√πng b·∫£n Enriched cho Phase 1)
DATA_P1="data/processed/red_phase1_enriched_v2.jsonl"
DATA_P2="data/processed/red_v40_phase2_reasoning.jsonl"
OUTPUT_ROOT="experiments_remote_optimized"

echo "üöÄ Starting Optimized Training Pipeline for $MODEL_NAME..."

# --- HYPERPARAMETERS SETUP ---
# T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tham s·ªë d·ª±a tr√™n size model ƒë·ªÉ tr√°nh OOM (Out of Memory)
if [[ "$MODEL_NAME" == *"14B"* ]]; then
    echo "‚öôÔ∏è Config for 14B Model (High VRAM usage)"
    BATCH_SIZE=1          # Gi·∫£m batch size ƒë·ªÉ kh√¥ng tr√†n VRAM 24GB
    GRAD_ACCUM=16         # TƒÉng t√≠ch l≈©y ƒë·ªÉ gi·ªØ effective batch size ~16
    LORA_R=64             # Rank cao cho model l·ªõn
    LORA_ALPHA=128
    LR="1e-4"             # Learning rate an to√†n
elif [[ "$MODEL_NAME" == *"7B"* ]] || [[ "$MODEL_NAME" == *"8B"* ]]; then
    echo "‚öôÔ∏è Config for 7B/8B Model"
    BATCH_SIZE=4
    GRAD_ACCUM=4
    LORA_R=32
    LORA_ALPHA=64
    LR="2e-4"
else
    # Default / Small models
    BATCH_SIZE=4
    GRAD_ACCUM=4
    LORA_R=16
    LORA_ALPHA=32
    LR="2e-4"
fi

# --- PHASE 1: BASE SFT (Ki·∫øn th·ª©c n·ªÅn) ---
echo "--- Phase 1: Base SFT (Enriched Data) ---"
# Epoch = 1 l√† ƒë·ªß cho 40k samples ƒë·ªÉ tr√°nh catastrophic forgetting
cat <<EOF > config_p1_opt.yaml
model_name: "$MODEL_NAME"
train_path: "$DATA_P1"
output_dir: "$OUTPUT_ROOT/phase1_sft"
load_in_4bit: true
lora_r: $LORA_R
lora_alpha: $LORA_ALPHA
lora_dropout: 0.05
num_train_epochs: 1
per_device_train_batch_size: $BATCH_SIZE
gradient_accumulation_steps: $GRAD_ACCUM
learning_rate: $LR
logging_steps: 10
save_steps: 200
max_length: 2048
use_auth_token_env: "HF_TOKEN"
EOF

python3 scripts/train_red.py --config config_p1_opt.yaml
echo "‚úÖ Phase 1 Complete."

# --- PHASE 2: REASONING (T∆∞ duy) ---
echo "--- Phase 2: Legacy Reasoning ---"
# Phase 2 dataset th∆∞·ªùng nh·ªè h∆°n, c√≥ th·ªÉ train 2-3 epochs
cat <<EOF > config_p2_opt.yaml
model_name: "$MODEL_NAME"
train_path: "$DATA_P2"
output_dir: "$OUTPUT_ROOT/phase2_reasoning"
load_in_4bit: true
lora_r: $LORA_R
lora_alpha: $LORA_ALPHA
lora_dropout: 0.05
num_train_epochs: 2
per_device_train_batch_size: $BATCH_SIZE
gradient_accumulation_steps: $GRAD_ACCUM
learning_rate: $LR
logging_steps: 10
save_steps: 100
max_length: 2048 
use_auth_token_env: "HF_TOKEN"
EOF

python3 scripts/train_red.py --config config_p2_opt.yaml
echo "‚úÖ Phase 2 Complete."

echo "üéâ DONE! Adapters saved in $OUTPUT_ROOT"
tar -czvf adapters_optimized_$(date +%Y%m%d).tar.gz $OUTPUT_ROOT
```

## 4. L·ªùi khuy√™n v·∫≠n h√†nh

*   **Flash Attention:** Tr√™n server, nh·ªõ c√†i `pip install flash-attn --no-build-isolation` ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô train g·∫•p 2-3 l·∫ßn cho model Qwen/Llama.
*   **Monitoring:** M·ªü th√™m m·ªôt terminal ch·∫°y `watch -n 1 nvidia-smi` ƒë·ªÉ theo d√µi VRAM. N·∫øu th·∫•y g·∫ßn full (23xxx MiB), h√£y stop v√† gi·∫£m `BATCH_SIZE` xu·ªëng 1 ngay l·∫≠p t·ª©c.
