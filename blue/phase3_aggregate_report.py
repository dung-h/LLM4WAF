import json
import os
import sys
import argparse
from collections import Counter, defaultdict
from datetime import datetime

# Add project root to path for imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# --- Mes.log function ---
def log_message(cmd, status, output_file=""):
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    log_entry = f"{timestamp} CMD=\"{cmd}\" STATUS={status}"
    if output_file:
        log_entry += f" OUTPUT=\"{output_file}\""
    with open("mes.log", "a", encoding="utf-8") as f:
        f.write(log_entry + "\n")

def main():
    parser = argparse.ArgumentParser(description="Aggregate BLUE LLM suggestions into a human-readable report.")
    parser.add_argument("--input_file", type=str, default="data/blue/blue_phase3_suggestions.jsonl",
                        help="Path to the suggestions JSONL file generated by runner_phase3_suggest.py.")
    parser.add_argument("--output_file", type=str, default="data/blue/blue_phase3_report.txt",
                        help="Path to save the generated report text file.")
    args = parser.parse_args()

    cmd_str = f"python blue/phase3_aggregate_report.py --input_file {args.input_file} --output_file {args.output_file}"

    try:
        if not os.path.exists(args.input_file):
            raise FileNotFoundError(f"Error: Suggestions file not found at {args.input_file}. Please run runner_phase3_suggest.py first.")

        suggestions = []
        with open(args.input_file, 'r', encoding='utf-8') as f:
            for line in f:
                suggestions.append(json.loads(line.strip()))
        
        total_analyzed_episodes = len(suggestions)
        
        # Statistics
        false_negative_count = 0
        vuln_effect_counts = Counter()
        recommended_rules_by_engine = defaultdict(Counter) # {engine: {rule_id: count}}
        top_actions = Counter() # Most frequent recommended actions
        llm_error_count = 0

        for s in suggestions:
            blue_output = s["blue_recommendation"]
            
            # Check for LLM errors/invalid JSON fallbacks
            if blue_output.get("recommended_actions") and \
               (f"LLM_ERROR_OR_INVALID_JSON_{s.get('blue_backend', 'UNKNOWN').upper()}" in blue_output.get("recommended_actions")[0] or \
                "LLM_RESPONSE_VALIDATION_ERROR" in blue_output.get("recommended_actions")[0]):
                llm_error_count += 1
            else:
                if blue_output.get("is_false_negative"):
                    false_negative_count += 1
                
                vuln_effect_counts[blue_output.get("vuln_effect", "UNKNOWN")] += 1
                
                for rule in blue_output.get("recommended_rules", []):
                    engine = rule.get("engine", "UNKNOWN")
                    rule_id = rule.get("rule_id", "UNKNOWN")
                    recommended_rules_by_engine[engine][rule_id] += 1
                    
                for action in blue_output.get("recommended_actions", []):
                    top_actions[action] += 1

        # Generate Report
        report_content = []
        report_content.append(f"BLUE Phase 3 â€“ WAF Tuning Summary (Backend: {suggestions[0].get('blue_backend', 'N/A').upper()})")
        report_content.append("=================================")
        report_content.append(f"\nTotal analyzed episodes: {total_analyzed_episodes}")
        report_content.append(f"Episodes with successful JSON parsing: {total_analyzed_episodes - llm_error_count}")
        report_content.append(f"Episodes where LLM returned parsing error: {llm_error_count}")
        report_content.append(f"False negatives (after valid JSON): {false_negative_count}")
        
        report_content.append("\nVuln Effect Distribution (from valid JSON):")
        if not vuln_effect_counts:
            report_content.append("- No valid vulnerability effects reported.")
        else:
            for effect, count in vuln_effect_counts.most_common():
                report_content.append(f"- {effect}: {count} episodes")

        report_content.append("\nPer-engine recommended rules (from valid JSON):")
        if not recommended_rules_by_engine:
            report_content.append("- No specific rules recommended.")
        else:
            for engine, rules_counter in recommended_rules_by_engine.items():
                report_content.append(f"- {engine}:")
                for rule_id, count in rules_counter.most_common():
                    report_content.append(f"    - {rule_id}: {count} episodes")
        
        report_content.append("\nTop Recommended Actions (from valid JSON):")
        if not top_actions:
            report_content.append("- No specific actions recommended.")
        else:
            for action, count in top_actions.most_common(5): # Top 5 actions
                report_content.append(f"- {action} ({count} episodes)")

        # Save report
        os.makedirs(os.path.dirname(args.output_file), exist_ok=True)
        with open(args.output_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_content))

        print(f"\nReport saved to {args.output_file}")
        print("\n" + "\n".join(report_content))
        log_message(cmd_str, "OK", args.output_file)

    except FileNotFoundError as e:
        print(e, file=sys.stderr)
        log_message(cmd_str, "FAIL", str(e))
    except Exception as e:
        print(f"Error running phase3_aggregate_report.py: {e}", file=sys.stderr)
        log_message(cmd_str, "FAIL", str(e))

if __name__ == "__main__":
    main()