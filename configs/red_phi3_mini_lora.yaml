# Configuration for Llama-3.2-3B-Instruct fine-tuning
# This file will be used by scripts/train_red.py

model_name: "microsoft/Phi-3-mini-4k-instruct"
adapter_name: "red_phi3_mini_lora"
prompt_format_type: "phi3_instruct"

# Dataset paths and fields
train_path: "data/processed/v13_sft_data.jsonl"
eval_path: "data/processed/red_test_v6_multi_clean.jsonl"
text_fields: ["instruction", "context", "constraints", "payload", "reasoning"]

# Training parameters
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
per_device_train_batch_size: 1 # Keep small for 8GB VRAM
gradient_accumulation_steps: 4 # Accumulate gradients to simulate larger batch size
learning_rate: 2e-4
num_train_epochs: 5
fp16: true # Use mixed precision training
optim: "paged_adamw_8bit" # Memory efficient optimizer
logging_steps: 1
save_steps: 50
output_dir: "experiments/red_phi3_mini_lora_v13_adapter"
max_seq_length: 512 # Max sequence length for training
