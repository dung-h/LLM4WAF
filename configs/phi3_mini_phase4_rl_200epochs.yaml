# Phi-3 Mini RL Training from Phase 3 Enhanced Adapter
# 200 epochs with DynamicCache fix

# Model
base_model: "microsoft/Phi-3-mini-4k-instruct"
adapter_path: "experiments/red_phase3_lightweight_enhanced_phi3/checkpoint-314"
model_type: "phi3"

# Training
output_dir: "experiments/phi3_mini_phase4_rl_200"
epochs: 150 # Reduced from 200 for consistency
batch_size: 1
lr: 1e-6
max_new_tokens: 64
max_context_length: 384

# WAF Configuration
waf_url: "http://modsec.llmshield.click"

use_auth_token_env: "HF_TOKEN"
