# Combined Phase 1 + Phase 2 Training Config
# Purpose: Train single adapter that handles BOTH prompt formats
# Strategy: Continual training with mixed dataset to prevent catastrophic forgetting

model_name: "microsoft/Phi-3-mini-4k-instruct"
train_path: "data/processed/red_phase1_phase2_combined.jsonl"
output_dir: "experiments/red_phase1_phase2_combined_phi3"

# Training parameters
num_train_epochs: 3
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
learning_rate: 5.0e-5 # Lower than Phase 1 to preserve existing knowledge
max_seq_length: 2048

# Quantization (for 8GB VRAM)
load_in_4bit: true
bnb_4bit_quant_type: "nf4"
bnb_4bit_use_double_quant: true
bnb_4bit_compute_dtype: "float16"

# LoRA configuration
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
target_modules:
  ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# Logging and checkpointing
logging_steps: 10
save_steps: 200
save_total_limit: 3
gradient_checkpointing: true
use_auth_token_env: "HF_TOKEN"
# Evaluation (optional)
# eval_path: "data/processed/red_phase1_phase2_eval.jsonl"
# evaluation_strategy: "steps"
# eval_steps: 200
